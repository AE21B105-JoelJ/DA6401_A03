{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620fc1d6",
   "metadata": {},
   "source": [
    "# Attention Seq2Seq Report Tester Notebook\n",
    "This notebook is used to take the best model from the sweep retrain the model using appropriate callbacks and then predict on the test set and save it and also create some visualizations if required. Without much details lets get into the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193dd313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:14:55.740961Z",
     "iopub.status.busy": "2025-05-19T20:14:55.740678Z",
     "iopub.status.idle": "2025-05-19T20:15:12.708432Z",
     "shell.execute_reply": "2025-05-19T20:15:12.707909Z",
     "shell.execute_reply.started": "2025-05-19T20:14:55.740937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mae21b105\u001b[0m (\u001b[33mRough\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the necessary libraries #\n",
    "# Importing the necessary libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as Fn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "wandb.login(key = \"5ef7c4bbfa350a2ffd3c198cb9289f544e3a0910\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39753f99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:15:16.619045Z",
     "iopub.status.busy": "2025-05-19T20:15:16.618568Z",
     "iopub.status.idle": "2025-05-19T20:15:16.776274Z",
     "shell.execute_reply": "2025-05-19T20:15:16.775719Z",
     "shell.execute_reply.started": "2025-05-19T20:15:16.619024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "# Loading the dataset\n",
    "df_train = pd.read_csv('/kaggle/input/dl-a3-tamil/ta_lexicons/ta.translit.sampled.train.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "df_test = pd.read_csv('/kaggle/input/dl-a3-tamil/ta_lexicons/ta.translit.sampled.test.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "df_val = pd.read_csv('/kaggle/input/dl-a3-tamil/ta_lexicons/ta.translit.sampled.dev.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdebd95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:15:20.205515Z",
     "iopub.status.busy": "2025-05-19T20:15:20.205046Z",
     "iopub.status.idle": "2025-05-19T20:15:20.217476Z",
     "shell.execute_reply": "2025-05-19T20:15:20.216727Z",
     "shell.execute_reply.started": "2025-05-19T20:15:20.205486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing the dataset for the model to fit #\n",
    "class Dataset_Tamil(Dataset):\n",
    "    def __init__(self, dataframe, build_vocab=True, input_token_index=None, output_token_index=None,\n",
    "                 max_enc_seq_len=0, max_dec_seq_len=0):\n",
    "        \n",
    "        # Input variables\n",
    "        self.input_df = dataframe\n",
    "        self.input_words = []\n",
    "        self.output_words = []\n",
    "        # Characters of the language\n",
    "        self.input_characters = set()\n",
    "        self.output_characters = set()\n",
    "\n",
    "        # Iterating thorough the rows\n",
    "        for _, row in self.input_df.iterrows():\n",
    "            input_word = str(row[\"latin\"])\n",
    "            output_word = \"\\t\" + str(row[\"native\"]) + \"\\n\"\n",
    "            self.input_words.append(input_word)\n",
    "            self.output_words.append(output_word)\n",
    "        \n",
    "        if build_vocab:\n",
    "            self.build_vocab()\n",
    "        else:\n",
    "            # Token index for sequence building\n",
    "            self.input_token_index = input_token_index\n",
    "            self.output_token_index = output_token_index\n",
    "            # Heuristics lengths for the encoder decoder\n",
    "            self.max_enc_seq_len = max_enc_seq_len\n",
    "            self.max_dec_seq_len = max_dec_seq_len\n",
    "\n",
    "        # Finding the encoder/decoder tokens \n",
    "        self.total_encoder_tokens = len(self.input_token_index)\n",
    "        self.total_decoder_tokens = len(self.output_token_index)\n",
    "\n",
    "    def build_vocab(self):\n",
    "        # Building the vocabulary\n",
    "        self.input_characters = sorted(set(\" \".join(self.input_words)))\n",
    "        self.output_characters = sorted(set(\" \".join(self.output_words)))\n",
    "        # Adding the padding character if not present\n",
    "        if \" \" not in self.input_characters:\n",
    "            self.input_characters.append(\" \")\n",
    "        if \" \" not in self.output_characters:\n",
    "            self.output_characters.append(\" \")\n",
    "\n",
    "        # Fitting/Finding the necessary values from training data\n",
    "        self.input_token_index = {char: i for i, char in enumerate(self.input_characters)}\n",
    "        self.output_token_index = {char: i for i, char in enumerate(self.output_characters)}\n",
    "\n",
    "        self.input_token_index_reversed = {i: char for i, char in enumerate(self.input_characters)}\n",
    "        self.output_token_index_reversed = {i: char for i, char in enumerate(self.output_characters)}\n",
    "\n",
    "        self.max_enc_seq_len = max(len(txt) for txt in self.input_words)\n",
    "        self.max_dec_seq_len = max(len(txt) for txt in self.output_words)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_words)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_word = self.input_words[index]\n",
    "        output_word = self.output_words[index]\n",
    "\n",
    "        # Finding the input for each stages of the network\n",
    "        encoder_input = np.zeros((self.max_enc_seq_len, self.total_encoder_tokens), dtype=np.float32)\n",
    "        decoder_input = np.zeros((self.max_dec_seq_len, self.total_decoder_tokens), dtype=np.float32)\n",
    "        decoder_output = np.zeros((self.max_dec_seq_len, self.total_decoder_tokens), dtype=np.float32)\n",
    "\n",
    "        for t, char in enumerate(input_word):\n",
    "            if char in self.input_token_index:\n",
    "                encoder_input[t, self.input_token_index[char]] = 1.0\n",
    "        for t in range(len(input_word), self.max_enc_seq_len):\n",
    "            encoder_input[t, self.input_token_index[\" \"]] = 1.0\n",
    "\n",
    "        for t, char in enumerate(output_word):\n",
    "            if char in self.output_token_index:\n",
    "                decoder_input[t, self.output_token_index[char]] = 1.0\n",
    "                if t > 0:\n",
    "                    decoder_output[t - 1, self.output_token_index[char]] = 1.0\n",
    "        # Fill remaining positions with space character\n",
    "        for t in range(len(output_word), self.max_dec_seq_len):\n",
    "            decoder_input[t, self.output_token_index[\" \"]] = 1.0\n",
    "            \n",
    "        for t in range(len(output_word) - 1, self.max_dec_seq_len):\n",
    "            decoder_output[t, self.output_token_index[\" \"]] = 1.0\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(encoder_input),\n",
    "            torch.from_numpy(decoder_input),\n",
    "            torch.from_numpy(decoder_output)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa433590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:15:22.185678Z",
     "iopub.status.busy": "2025-05-19T20:15:22.185236Z",
     "iopub.status.idle": "2025-05-19T20:15:22.207349Z",
     "shell.execute_reply": "2025-05-19T20:15:22.206581Z",
     "shell.execute_reply.started": "2025-05-19T20:15:22.185652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model classes definitions #\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3, cell_type=\"RNN\", num_layers=1, bi_directional=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type.upper()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.enc = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.enc = nn.GRU(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "        else:\n",
    "            self.enc = nn.RNN(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            hidden, (hn, cn) = self.enc(x)\n",
    "            return hidden, (hn, cn)\n",
    "        else:\n",
    "            hidden, out = self.enc(x)\n",
    "            return hidden, out\n",
    "        \n",
    "class Attention_Mechanism(nn.Module):\n",
    "    def __init__(self, hidden_dim, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        # Creating the matrices for attention calculation\n",
    "        self.V_att = nn.Parameter(torch.randn(size=(self.hidden_dim, 1), device=device)*0.1)\n",
    "        self.U_att = nn.Parameter(torch.randn(size=(self.hidden_dim, self.hidden_dim), device=device)*0.1)\n",
    "        self.W_att = nn.Parameter(torch.randn(size=(self.hidden_dim, self.hidden_dim), device=device)*0.1)\n",
    "\n",
    "    def forward(self, st_1, c_j, mask):\n",
    "        # Compute the attention scores and softmax\n",
    "        \"\"\"\n",
    "        st_1 : input of size (bx1xd)\n",
    "        c_j : input of size (bxLxd)\n",
    "        \"\"\"\n",
    "        #print(st_1.shape, c_j.shape)\n",
    "        inside = self.tanh(torch.matmul(c_j, self.W_att) + torch.matmul(st_1, self.U_att))\n",
    "        #print(inside.shape)\n",
    "        scores = torch.matmul(inside, self.V_att).squeeze(2)\n",
    "        #print(scores.shape)\n",
    "        scores[mask] = -torch.inf\n",
    "\n",
    "        attention = self.softmax(scores)\n",
    "        return attention\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3, cell_type='RNN', num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.cell_type = cell_type.upper()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.dec = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.dec = nn.GRU(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        else:\n",
    "            self.dec = nn.RNN(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "\n",
    "    def forward(self, x, states):\n",
    "        if states == None:\n",
    "            hidden, out = self.dec(x)\n",
    "            return hidden, out\n",
    "        elif type(states) == tuple:\n",
    "            hidden, (hn, cn) = self.dec(x, states)\n",
    "            return hidden, (hn, cn)\n",
    "        else:\n",
    "            hidden, out = self.dec(x, states)\n",
    "            return hidden, out\n",
    "        \n",
    "class Attention_Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_token_index, output_token_index, max_dec_seq_len, embedding_dim,hidden_size_enc, bi_directional=False,\n",
    "            nature=\"train\", enc_cell=\"LSTM\", dec_cell=\"LSTM\", num_layers=1,dropout=0.2, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_index_token = input_token_index\n",
    "        self.output_index_token = output_token_index\n",
    "        self.max_dec_seq_len = max_dec_seq_len\n",
    "        self.nature = nature\n",
    "        self.enc_cell_type = enc_cell.upper()\n",
    "        self.dec_cell_type = dec_cell.upper()\n",
    "        self.num_layers= num_layers\n",
    "        self.bi_directional = bi_directional\n",
    "        self.hidden_size_enc = hidden_size_enc\n",
    "        self.hidden_size_dec = (1 + int(self.bi_directional == True))*hidden_size_enc\n",
    "        self.embedding = nn.Linear(in_features=len(self.input_index_token), out_features=embedding_dim)\n",
    "        self.embedding_act = nn.Tanh()\n",
    "        self.encoder = Encoder(input_size=embedding_dim, hidden_size=hidden_size_enc, dropout=dropout, cell_type=enc_cell, num_layers=num_layers, bi_directional=self.bi_directional).to(device)\n",
    "        self.attention = Attention_Mechanism(hidden_dim=self.hidden_size_dec)\n",
    "        self.decoder = Decoder(input_size=len(self.output_index_token)+self.hidden_size_dec, hidden_size=self.hidden_size_dec, dropout=dropout, cell_type=dec_cell, num_layers=num_layers).to(device)\n",
    "        self.device = device\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.fc = nn.Linear(in_features=self.hidden_size_dec, out_features=len(output_token_index))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "        DEC_IN = DEC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        mask_ = torch.argmax(ENC_IN, 2) == 2\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "        # Final matrix\n",
    "        final_out = torch.zeros(batch_size, self.max_dec_seq_len, len(self.output_index_token), device=self.device)\n",
    "\n",
    "        # Initial decoder input (with start token)\n",
    "        in_ = DEC_IN[:, 0:1, :].clone()\n",
    "        for t in range(self.max_dec_seq_len):\n",
    "            if t==0:\n",
    "                out_step, states_dec = self.decoder(torch.cat((in_, hidden_enc[:,-1,:].unsqueeze(1)), dim=2), None) \n",
    "            else:\n",
    "                # input for next input\n",
    "                in_ = DEC_IN[:, t, :].unsqueeze(1).clone()\n",
    "                att_scores = self.attention(out_step, hidden_enc, mask_)\n",
    "\n",
    "                in_ = torch.cat((in_, torch.bmm(att_scores.unsqueeze(1), hidden_enc)), dim=2)\n",
    "                # Output\n",
    "                out_step, states_dec = self.decoder(in_, states_dec)  \n",
    "\n",
    "            logits_step = self.fc(out_step.squeeze(1))            \n",
    "            final_out[:, t, :] = logits_step\n",
    "   \n",
    "        return final_out\n",
    "    \n",
    "    def predict_greedy(self, batch):\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "        DEC_IN = DEC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        mask_ = torch.argmax(ENC_IN, 2) == 2\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "        # Final matrix\n",
    "        final_out = torch.zeros(batch_size, self.max_dec_seq_len, len(self.output_index_token), device=self.device)\n",
    "\n",
    "        # Initial decoder input (with start token)\n",
    "        in_ = torch.zeros(batch_size, 1, len(self.output_index_token), device=self.device)\n",
    "        in_[:, 0, 0] = 1.0\n",
    "\n",
    "        for t in range(self.max_dec_seq_len):\n",
    "            if t==0:\n",
    "                out_step, states_dec = self.decoder(torch.cat((in_, hidden_enc[:,-1,:].unsqueeze(1)), dim=2), None)  \n",
    "            else:\n",
    "                out_step, states_dec = self.decoder(in_, states_dec)  \n",
    "\n",
    "            logits_step = self.fc(out_step.squeeze(1))            \n",
    "            final_out[:, t, :] = logits_step\n",
    "\n",
    "            # Greedy argmax for next input\n",
    "            top1 = torch.argmax(logits_step, dim=1)               \n",
    "            in_ = torch.zeros(batch_size, 1, len(self.output_index_token), device=self.device)\n",
    "            in_[torch.arange(batch_size), 0, top1] = 1.0\n",
    "            att_scores = self.attention(out_step, hidden_enc, mask_)\n",
    "\n",
    "            in_ = torch.cat((in_, torch.bmm(att_scores.unsqueeze(1), hidden_enc)), dim=2)\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09107525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:21:39.205664Z",
     "iopub.status.busy": "2025-05-19T20:21:39.205206Z",
     "iopub.status.idle": "2025-05-19T20:21:39.213873Z",
     "shell.execute_reply": "2025-05-19T20:21:39.213140Z",
     "shell.execute_reply.started": "2025-05-19T20:21:39.205642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fucntion for validation of the model # \n",
    "def validate_seq2seq(model, val_loader, device, val_type = \"greedy\", beam_width=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    correct_words = 0\n",
    "    total_words = 0\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_progress = tqdm(val_loader, desc=\"Predicting...\")\n",
    "        for batch in tqdm_progress:\n",
    "            ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "            ENC_IN = ENC_IN.to(device)\n",
    "            DEC_IN = DEC_IN.to(device)\n",
    "            DEC_OUT = DEC_OUT.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            decoder_output = model(batch)\n",
    "\n",
    "            # Compute loss\n",
    "            vocab_size = decoder_output.size(-1)\n",
    "            decoder_output = decoder_output.view(-1, vocab_size)\n",
    "            decoder_target_indices = DEC_OUT.argmax(dim=-1).view(-1)\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target_indices)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Character-wise accuracy\n",
    "            if val_type == \"greedy\":\n",
    "                decoder_output = model.predict_greedy(batch)\n",
    "            else:\n",
    "                decoder_output = model.predict_beam_search(batch, beam_width=beam_width)\n",
    "\n",
    "            #print(decoder_output.shape)\n",
    "            pred_tokens = decoder_output.argmax(dim=2)\n",
    "            true_tokens = DEC_OUT.argmax(dim=2)\n",
    "            #print(pred_tokens.shape)\n",
    "            #print(true_tokens.shape)\n",
    "            \n",
    "            mask = true_tokens != 2  # Ignore PAD tokens\n",
    "            correct_chars += (pred_tokens[mask] == true_tokens[mask]).sum().item()\n",
    "            total_chars += mask.sum().item()\n",
    "\n",
    "            mask = true_tokens != 2  # Ignore PAD tokens\n",
    "            #print(mask.shape)\n",
    "            total_words += decoder_output.shape[0]\n",
    "            #print(pred_tokens[mask].shape)\n",
    "            chk_words = (mask.int() - (pred_tokens == true_tokens).int())\n",
    "            chk_words[mask == False] = 0\n",
    "            correct_words += (chk_words.sum(dim = 1) == 0).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_chars / total_chars if total_chars > 0 else 0.0\n",
    "    word_acc = correct_words / total_words if total_words > 0 else 0.0\n",
    "    return avg_loss, accuracy, word_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b502a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:21:39.944977Z",
     "iopub.status.busy": "2025-05-19T20:21:39.944708Z",
     "iopub.status.idle": "2025-05-19T20:21:39.953207Z",
     "shell.execute_reply": "2025-05-19T20:21:39.952568Z",
     "shell.execute_reply.started": "2025-05-19T20:21:39.944959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainloop\n",
    "def train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs, device, beam_sizes = [3,5], run=None):\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=2)  # 2 is the padding index\n",
    "    max_val_char_acc = 0\n",
    "    max_val_word_acc = 0\n",
    "    print(\"Training of the model has started...\")\n",
    "    counter = 0\n",
    "    patience = 7\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        tqdm_loader = tqdm(train_loader, desc=f\"Epoch : {epoch + 1} \", ncols=100)\n",
    "\n",
    "        for batch in tqdm_loader:\n",
    "            ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "            ENC_IN = ENC_IN.to(device)\n",
    "            DEC_IN = DEC_IN.to(device)\n",
    "            DEC_OUT = DEC_OUT.to(device)\n",
    "            # Move to device\n",
    "            decoder_output = model(batch)\n",
    "\n",
    "            # Reshape for loss\n",
    "            decoder_output = decoder_output.view(-1, decoder_output.size(-1))\n",
    "            decoder_target_indices = DEC_OUT.argmax(dim=-1).view(-1)\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target_indices)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            tqdm_loader.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        val_loss, val_acc, val_word_acc = validate_seq2seq(model, val_loader, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val Word Acc: {val_word_acc:.4f}\")\n",
    "\n",
    "        if run is not None:\n",
    "            run.log({\"train_loss_epoch\" : avg_loss, \"val_loss_epoch\" : val_loss, \"val_char_acc\" : val_acc, \"val_word_acc\" : val_word_acc})\n",
    "\n",
    "        if val_word_acc > max_val_word_acc:\n",
    "            max_val_char_acc = val_acc\n",
    "            max_val_word_acc = val_word_acc\n",
    "            torch.save(model.state_dict(),\"Attention_Best_model.pth\")\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter > patience:\n",
    "            break\n",
    "\n",
    "    if run is not None:\n",
    "        run.summary[\"max_val_char_acc\"] = max_val_char_acc\n",
    "        run.summary[\"max_val_word_acc\"] = max_val_word_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ce3865d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:21:43.537464Z",
     "iopub.status.busy": "2025-05-19T20:21:43.537005Z",
     "iopub.status.idle": "2025-05-19T20:31:59.708898Z",
     "shell.execute_reply": "2025-05-19T20:31:59.708263Z",
     "shell.execute_reply.started": "2025-05-19T20:21:43.537441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_202143-qwnwzig8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/A3_DA6401_DL/Attention_RNN/runs/qwnwzig8' target=\"_blank\">Best Model Attention S2S</a></strong> to <a href='https://wandb.ai/A3_DA6401_DL/Attention_RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/A3_DA6401_DL/Attention_RNN' target=\"_blank\">https://wandb.ai/A3_DA6401_DL/Attention_RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/A3_DA6401_DL/Attention_RNN/runs/qwnwzig8' target=\"_blank\">https://wandb.ai/A3_DA6401_DL/Attention_RNN/runs/qwnwzig8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the model has started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 1 : 100%|████████████████████████████████| 267/267 [00:27<00:00,  9.75it/s, Train Loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 2.1953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Val Loss: 1.0201 | Val Acc: 0.5758 | Val Word Acc: 0.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 2 : 100%|███████████████████████████████| 267/267 [00:27<00:00,  9.73it/s, Train Loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] | Train Loss: 0.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] | Val Loss: 0.4789 | Val Acc: 0.8109 | Val Word Acc: 0.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 3 : 100%|███████████████████████████████| 267/267 [00:27<00:00,  9.73it/s, Train Loss=0.323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] | Train Loss: 0.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] | Val Loss: 0.4016 | Val Acc: 0.8299 | Val Word Acc: 0.4777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 4 : 100%|███████████████████████████████| 267/267 [00:27<00:00,  9.62it/s, Train Loss=0.242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] | Train Loss: 0.3340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] | Val Loss: 0.3748 | Val Acc: 0.8424 | Val Word Acc: 0.5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 5 : 100%|███████████████████████████████| 267/267 [00:27<00:00,  9.56it/s, Train Loss=0.245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] | Train Loss: 0.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] | Val Loss: 0.3508 | Val Acc: 0.8493 | Val Word Acc: 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 6 : 100%|███████████████████████████████| 267/267 [00:27<00:00,  9.66it/s, Train Loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] | Train Loss: 0.2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] | Val Loss: 0.3392 | Val Acc: 0.8464 | Val Word Acc: 0.5553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 7 : 100%|███████████████████████████████| 267/267 [00:27<00:00,  9.63it/s, Train Loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] | Train Loss: 0.2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] | Val Loss: 0.3242 | Val Acc: 0.8575 | Val Word Acc: 0.5859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 8 : 100%|███████████████████████████████| 267/267 [00:27<00:00,  9.61it/s, Train Loss=0.154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] | Train Loss: 0.2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] | Val Loss: 0.3244 | Val Acc: 0.8559 | Val Word Acc: 0.5812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 9 : 100%|███████████████████████████████| 267/267 [00:27<00:00,  9.62it/s, Train Loss=0.208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] | Train Loss: 0.2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] | Val Loss: 0.3116 | Val Acc: 0.8651 | Val Word Acc: 0.6102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 10 : 100%|██████████████████████████████| 267/267 [00:27<00:00,  9.61it/s, Train Loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] | Train Loss: 0.1887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] | Val Loss: 0.3146 | Val Acc: 0.8632 | Val Word Acc: 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 11 : 100%|██████████████████████████████| 267/267 [00:27<00:00,  9.69it/s, Train Loss=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] | Train Loss: 0.1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] | Val Loss: 0.3227 | Val Acc: 0.8603 | Val Word Acc: 0.6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 12 : 100%|██████████████████████████████| 267/267 [00:27<00:00,  9.68it/s, Train Loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] | Train Loss: 0.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] | Val Loss: 0.3167 | Val Acc: 0.8678 | Val Word Acc: 0.6164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 13 : 100%|██████████████████████████████| 267/267 [00:27<00:00,  9.63it/s, Train Loss=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] | Train Loss: 0.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] | Val Loss: 0.3198 | Val Acc: 0.8637 | Val Word Acc: 0.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 14 : 100%|██████████████████████████████| 267/267 [00:27<00:00,  9.54it/s, Train Loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] | Train Loss: 0.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] | Val Loss: 0.3204 | Val Acc: 0.8586 | Val Word Acc: 0.6111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 15 : 100%|██████████████████████████████| 267/267 [00:28<00:00,  9.49it/s, Train Loss=0.135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] | Train Loss: 0.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] | Val Loss: 0.3353 | Val Acc: 0.8630 | Val Word Acc: 0.6096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 16 : 100%|██████████████████████████████| 267/267 [00:28<00:00,  9.44it/s, Train Loss=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] | Train Loss: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] | Val Loss: 0.3285 | Val Acc: 0.8651 | Val Word Acc: 0.6225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 17 : 100%|██████████████████████████████| 267/267 [00:28<00:00,  9.49it/s, Train Loss=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] | Train Loss: 0.1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] | Val Loss: 0.3320 | Val Acc: 0.8590 | Val Word Acc: 0.6115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 18 : 100%|██████████████████████████████| 267/267 [00:28<00:00,  9.48it/s, Train Loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] | Train Loss: 0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] | Val Loss: 0.3427 | Val Acc: 0.8567 | Val Word Acc: 0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 19 : 100%|██████████████████████████████| 267/267 [00:27<00:00,  9.54it/s, Train Loss=0.129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] | Train Loss: 0.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] | Val Loss: 0.3309 | Val Acc: 0.8632 | Val Word Acc: 0.6130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 20 : 100%|██████████████████████████████| 267/267 [00:27<00:00,  9.55it/s, Train Loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] | Train Loss: 0.1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] | Val Loss: 0.3385 | Val Acc: 0.8693 | Val Word Acc: 0.6244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "config = {\n",
    "        \"learning_rate\" : 0.001,\n",
    "        \"dropout_rnn\" : 0.2, \n",
    "        \"batch_size\" :  256,\n",
    "        \"epochs\" : 20,\n",
    "        \"embedding_dim\" : 256,\n",
    "        \"num_layers\" : 2,\n",
    "        \"hidden_size_enc\" : 128,\n",
    "        \"enc_cell_type\" : \"GRU\",\n",
    "        \"dec_cell_type\" : \"RNN\",\n",
    "        \"bi_directional\" : True,\n",
    "    }\n",
    "run = wandb.init(entity=\"A3_DA6401_DL\", project=\"Attention_RNN\", name=\"Best Model Attention S2S\", config=config)\n",
    "\n",
    "# Loading the datasets and dataloaders\n",
    "train_dataset = Dataset_Tamil(df_train)\n",
    "val_dataset = Dataset_Tamil(df_val, build_vocab=False, input_token_index=train_dataset.input_token_index, \n",
    "                            output_token_index=train_dataset.output_token_index, max_enc_seq_len=train_dataset.max_enc_seq_len,\n",
    "                            max_dec_seq_len=train_dataset.max_dec_seq_len)\n",
    "test_dataset = Dataset_Tamil(df_test, build_vocab=False, input_token_index=train_dataset.input_token_index, \n",
    "                            output_token_index=train_dataset.output_token_index, max_enc_seq_len=train_dataset.max_enc_seq_len,\n",
    "                            max_dec_seq_len=train_dataset.max_dec_seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Attention_Seq2Seq(input_token_index=train_dataset.input_token_index, output_token_index=train_dataset.output_token_index, max_dec_seq_len=train_dataset.max_dec_seq_len,\n",
    "                embedding_dim=config[\"embedding_dim\"], hidden_size_enc=config[\"hidden_size_enc\"], bi_directional=config[\"bi_directional\"], enc_cell=config[\"enc_cell_type\"], dec_cell=config[\"dec_cell_type\"], \n",
    "                num_layers=config[\"num_layers\"], dropout=config[\"dropout_rnn\"], device=device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs=config[\"epochs\"], device=device, run=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5493153b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:32:40.609409Z",
     "iopub.status.busy": "2025-05-19T20:32:40.609156Z",
     "iopub.status.idle": "2025-05-19T20:32:40.640866Z",
     "shell.execute_reply": "2025-05-19T20:32:40.640170Z",
     "shell.execute_reply.started": "2025-05-19T20:32:40.609390Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = Attention_Seq2Seq(input_token_index=train_dataset.input_token_index, output_token_index=train_dataset.output_token_index, max_dec_seq_len=train_dataset.max_dec_seq_len,\n",
    "                embedding_dim=config[\"embedding_dim\"], hidden_size_enc=config[\"hidden_size_enc\"], bi_directional=config[\"bi_directional\"], enc_cell=config[\"enc_cell_type\"], dec_cell=config[\"dec_cell_type\"], \n",
    "                num_layers=config[\"num_layers\"], dropout=config[\"dropout_rnn\"], device=device).to(device)\n",
    "\n",
    "model_best.load_state_dict(torch.load(\"/kaggle/working/Attention_Best_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff2ebbb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:33:09.433743Z",
     "iopub.status.busy": "2025-05-19T20:33:09.433432Z",
     "iopub.status.idle": "2025-05-19T20:33:11.998675Z",
     "shell.execute_reply": "2025-05-19T20:33:11.997991Z",
     "shell.execute_reply.started": "2025-05-19T20:33:09.433721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.33853095521529514, 0.8693159257318023, 0.6244324007616816)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_seq2seq(model_best, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a869d984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:33:34.602607Z",
     "iopub.status.busy": "2025-05-19T20:33:34.602205Z",
     "iopub.status.idle": "2025-05-19T20:33:37.158320Z",
     "shell.execute_reply": "2025-05-19T20:33:37.157513Z",
     "shell.execute_reply.started": "2025-05-19T20:33:34.602590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 100%|██████████| 27/27 [00:02<00:00, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8589120478549397 0.5996503496503497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "_, test_char_acc, test_word_acc = validate_seq2seq(model_best, test_loader, device)\n",
    "\n",
    "print(test_char_acc, test_word_acc)\n",
    "\n",
    "if run is not None:\n",
    "    run.summary[\"test_char_acc\"] = test_char_acc\n",
    "    run.summary[\"test_word_acc\"] = test_word_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1118eb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:33:43.692206Z",
     "iopub.status.busy": "2025-05-19T20:33:43.691944Z",
     "iopub.status.idle": "2025-05-19T20:33:43.700071Z",
     "shell.execute_reply": "2025-05-19T20:33:43.699289Z",
     "shell.execute_reply.started": "2025-05-19T20:33:43.692187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def write_outputs(model, data_loader, filename_csv):\n",
    "    tqdm_progress = tqdm(data_loader, desc=\"Writing...\")\n",
    "\n",
    "    list_in, list_out, list_pred = [], [], []\n",
    "    for batch in tqdm_progress:\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        out_pred = model.predict_greedy(batch)\n",
    "\n",
    "        for ix in range(ENC_IN.shape[0]):\n",
    "            str_in, str_out, str_pred = \"\", \"\", \"\"\n",
    "            input_word_vec = ENC_IN[ix].argmax(1)\n",
    "            output_word_vec = DEC_OUT[ix].argmax(1)\n",
    "            output_pred_vec = out_pred[ix].argmax(1)\n",
    "\n",
    "            for jx in range(train_dataset.max_dec_seq_len):\n",
    "                char = train_dataset.output_token_index_reversed[output_word_vec[jx].item()]\n",
    "                if char == \"\\n\":\n",
    "                    break\n",
    "                str_out += char                \n",
    "\n",
    "            for jx in range(train_dataset.max_dec_seq_len):\n",
    "                char = train_dataset.output_token_index_reversed[output_pred_vec[jx].item()]\n",
    "                if char == \"\\n\":\n",
    "                    break\n",
    "                str_pred += char      \n",
    "\n",
    "            for jx in range(train_dataset.max_enc_seq_len):\n",
    "                char = train_dataset.input_token_index_reversed[input_word_vec[jx].item()]\n",
    "                if char == \" \":\n",
    "                    break\n",
    "                str_in += char     \n",
    "\n",
    "            list_in.append(str_in)\n",
    "            list_out.append(str_out)\n",
    "            list_pred.append(str_pred)\n",
    "\n",
    "    pds = pd.DataFrame(data = {\"english\" : list_in, \"truth tamil\" : list_out, \"pred tamil\" : list_pred})\n",
    "    pds.to_csv(filename_csv, encoding=\"utf-8\", index=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59a2e730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T20:33:46.178660Z",
     "iopub.status.busy": "2025-05-19T20:33:46.178216Z",
     "iopub.status.idle": "2025-05-19T20:33:49.244712Z",
     "shell.execute_reply": "2025-05-19T20:33:49.243917Z",
     "shell.execute_reply.started": "2025-05-19T20:33:46.178640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing...: 100%|██████████| 27/27 [00:03<00:00,  8.89it/s]\n"
     ]
    }
   ],
   "source": [
    "write_outputs(model, test_loader, \"Attention_predictions_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7443057,
     "sourceId": 11846133,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
