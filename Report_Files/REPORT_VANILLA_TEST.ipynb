{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51387b6b",
   "metadata": {},
   "source": [
    "# Vanilla Seq2Seq Report Tester Notebook\n",
    "This notebook is used to take the best model from the sweep retrain the model using appropriate callbacks and then predict on the test set and save it and also create some visualizations if required. Without much details lets get into the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa392ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:32:41.402616Z",
     "iopub.status.busy": "2025-05-19T14:32:41.401905Z",
     "iopub.status.idle": "2025-05-19T14:32:52.381714Z",
     "shell.execute_reply": "2025-05-19T14:32:52.381108Z",
     "shell.execute_reply.started": "2025-05-19T14:32:41.402589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mae21b105\u001b[0m (\u001b[33mRough\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the necessary libraries #\n",
    "# Importing the necessary libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as Fn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "wandb.login(key = \"5ef7c4bbfa350a2ffd3c198cb9289f544e3a0910\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daff3a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:32:53.371033Z",
     "iopub.status.busy": "2025-05-19T14:32:53.370561Z",
     "iopub.status.idle": "2025-05-19T14:32:53.495491Z",
     "shell.execute_reply": "2025-05-19T14:32:53.494893Z",
     "shell.execute_reply.started": "2025-05-19T14:32:53.371010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "# Loading the dataset\n",
    "df_train = pd.read_csv('/kaggle/input/dl-a3-tamil/ta_lexicons/ta.translit.sampled.train.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "df_test = pd.read_csv('/kaggle/input/dl-a3-tamil/ta_lexicons/ta.translit.sampled.test.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "df_val = pd.read_csv('/kaggle/input/dl-a3-tamil/ta_lexicons/ta.translit.sampled.dev.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24374e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:32:54.655431Z",
     "iopub.status.busy": "2025-05-19T14:32:54.655109Z",
     "iopub.status.idle": "2025-05-19T14:32:54.667230Z",
     "shell.execute_reply": "2025-05-19T14:32:54.666539Z",
     "shell.execute_reply.started": "2025-05-19T14:32:54.655408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing the dataset for the model to fit #\n",
    "class Dataset_Tamil(Dataset):\n",
    "    def __init__(self, dataframe, build_vocab=True, input_token_index=None, output_token_index=None,\n",
    "                 max_enc_seq_len=0, max_dec_seq_len=0):\n",
    "        \n",
    "        # Input variables\n",
    "        self.input_df = dataframe\n",
    "        self.input_words = []\n",
    "        self.output_words = []\n",
    "        # Characters of the language\n",
    "        self.input_characters = set()\n",
    "        self.output_characters = set()\n",
    "\n",
    "        # Iterating thorough the rows\n",
    "        for _, row in self.input_df.iterrows():\n",
    "            input_word = str(row[\"latin\"])\n",
    "            output_word = \"\\t\" + str(row[\"native\"]) + \"\\n\"\n",
    "            self.input_words.append(input_word)\n",
    "            self.output_words.append(output_word)\n",
    "        \n",
    "        if build_vocab:\n",
    "            self.build_vocab()\n",
    "        else:\n",
    "            # Token index for sequence building\n",
    "            self.input_token_index = input_token_index\n",
    "            self.output_token_index = output_token_index\n",
    "            # Heuristics lengths for the encoder decoder\n",
    "            self.max_enc_seq_len = max_enc_seq_len\n",
    "            self.max_dec_seq_len = max_dec_seq_len\n",
    "\n",
    "        # Finding the encoder/decoder tokens \n",
    "        self.total_encoder_tokens = len(self.input_token_index)\n",
    "        self.total_decoder_tokens = len(self.output_token_index)\n",
    "\n",
    "    def build_vocab(self):\n",
    "        # Building the vocabulary\n",
    "        self.input_characters = sorted(set(\" \".join(self.input_words)))\n",
    "        self.output_characters = sorted(set(\" \".join(self.output_words)))\n",
    "        # Adding the padding character if not present\n",
    "        if \" \" not in self.input_characters:\n",
    "            self.input_characters.append(\" \")\n",
    "        if \" \" not in self.output_characters:\n",
    "            self.output_characters.append(\" \")\n",
    "\n",
    "        # Fitting/Finding the necessary values from training data\n",
    "        self.input_token_index = {char: i for i, char in enumerate(self.input_characters)}\n",
    "        self.output_token_index = {char: i for i, char in enumerate(self.output_characters)}\n",
    "\n",
    "        self.input_token_index_reversed = {i: char for i, char in enumerate(self.input_characters)}\n",
    "        self.output_token_index_reversed = {i: char for i, char in enumerate(self.output_characters)}\n",
    "\n",
    "        self.max_enc_seq_len = max(len(txt) for txt in self.input_words)\n",
    "        self.max_dec_seq_len = max(len(txt) for txt in self.output_words)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_words)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_word = self.input_words[index]\n",
    "        output_word = self.output_words[index]\n",
    "\n",
    "        # Finding the input for each stages of the network\n",
    "        encoder_input = np.zeros((self.max_enc_seq_len, self.total_encoder_tokens), dtype=np.float32)\n",
    "        decoder_input = np.zeros((self.max_dec_seq_len, self.total_decoder_tokens), dtype=np.float32)\n",
    "        decoder_output = np.zeros((self.max_dec_seq_len, self.total_decoder_tokens), dtype=np.float32)\n",
    "\n",
    "        for t, char in enumerate(input_word):\n",
    "            if char in self.input_token_index:\n",
    "                encoder_input[t, self.input_token_index[char]] = 1.0\n",
    "        for t in range(len(input_word), self.max_enc_seq_len):\n",
    "            encoder_input[t, self.input_token_index[\" \"]] = 1.0\n",
    "\n",
    "        for t, char in enumerate(output_word):\n",
    "            if char in self.output_token_index:\n",
    "                decoder_input[t, self.output_token_index[char]] = 1.0\n",
    "                if t > 0:\n",
    "                    decoder_output[t - 1, self.output_token_index[char]] = 1.0\n",
    "        # Fill remaining positions with space character\n",
    "        for t in range(len(output_word), self.max_dec_seq_len):\n",
    "            decoder_input[t, self.output_token_index[\" \"]] = 1.0\n",
    "\n",
    "        for t in range(len(output_word) - 1, self.max_dec_seq_len):\n",
    "            decoder_output[t, self.output_token_index[\" \"]] = 1.0\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(encoder_input),\n",
    "            torch.from_numpy(decoder_input),\n",
    "            torch.from_numpy(decoder_output)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4fa7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:32:56.069700Z",
     "iopub.status.busy": "2025-05-19T14:32:56.069133Z",
     "iopub.status.idle": "2025-05-19T14:32:56.099916Z",
     "shell.execute_reply": "2025-05-19T14:32:56.099102Z",
     "shell.execute_reply.started": "2025-05-19T14:32:56.069667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model classes definitions #\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3, cell_type=\"RNN\", num_layers=1, bi_directional=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type.upper()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.enc = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.enc = nn.GRU(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "        else:\n",
    "            self.enc = nn.RNN(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            hidden, (hn, cn) = self.enc(x)\n",
    "            return hidden, (hn, cn)\n",
    "        else:\n",
    "            hidden, out = self.enc(x)\n",
    "            return hidden, out\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3, cell_type='RNN', num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.cell_type = cell_type.upper()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.dec = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.dec = nn.GRU(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        else:\n",
    "            self.dec = nn.RNN(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "\n",
    "    def forward(self, x, states):\n",
    "        if type(states) == tuple:\n",
    "            hidden, (hn, cn) = self.dec(x, states)\n",
    "            return hidden, (hn, cn)\n",
    "        else:\n",
    "            hidden, out = self.dec(x, states)\n",
    "            return hidden, out\n",
    "        \n",
    "# Helper function\n",
    "def combine_directions(hidden):\n",
    "    layers = []\n",
    "    for i in range(0, hidden.size(0), 2):  \n",
    "        fwd = hidden[i]\n",
    "        bwd = hidden[i + 1]\n",
    "        combined = torch.cat((fwd, bwd), dim=-1) \n",
    "        layers.append(combined)\n",
    "    return torch.stack(layers)  \n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_token_index, output_token_index, max_dec_seq_len, embedding_dim,hidden_size_enc, bi_directional,\n",
    "            nature=\"train\", enc_cell=\"LSTM\", dec_cell=\"LSTM\", num_layers=1,dropout=0.2, device=\"cpu\"):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.input_index_token = input_token_index\n",
    "        self.output_index_token = output_token_index\n",
    "        self.max_dec_seq_len = max_dec_seq_len\n",
    "        self.nature = nature\n",
    "        self.enc_cell_type = enc_cell.upper()\n",
    "        self.dec_cell_type = dec_cell.upper()\n",
    "        self.num_layers= num_layers\n",
    "        self.bi_directional = bi_directional\n",
    "        self.hidden_size_enc = hidden_size_enc\n",
    "        self.hidden_size_dec = (1 + int(self.bi_directional == True))*hidden_size_enc\n",
    "        self.embedding = nn.Linear(in_features=len(self.input_index_token), out_features=embedding_dim)\n",
    "        self.embedding_act = nn.Tanh()\n",
    "        self.encoder = Encoder(input_size=embedding_dim, hidden_size=hidden_size_enc, dropout=dropout, cell_type=enc_cell, num_layers=num_layers, bi_directional=self.bi_directional).to(device)\n",
    "        self.decoder = Decoder(input_size=len(self.output_index_token), hidden_size=self.hidden_size_dec, dropout=dropout, cell_type=dec_cell, num_layers=num_layers).to(device)\n",
    "        self.device = device\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.fc = nn.Linear(in_features=self.hidden_size_dec, out_features=len(output_token_index))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "        DEC_IN = DEC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "        if self.bi_directional == True:\n",
    "            if self.enc_cell_type == \"LSTM\":\n",
    "                (h,c) = states_enc\n",
    "                states_enc = (combine_directions(h), combine_directions(c))\n",
    "            else:\n",
    "                states_enc = combine_directions(states_enc)\n",
    "\n",
    "        # Teacher forcing mode #    \n",
    "        # Making the states correctly formatted\n",
    "        if self.dec_cell_type == \"LSTM\": \n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc\n",
    "            else:\n",
    "                h = torch.zeros(self.num_layers, batch_size, self.decoder.hidden_size, device=self.device)\n",
    "                c = states_enc\n",
    "                states_dec = (h, c)\n",
    "        else:\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc[1]\n",
    "            else:\n",
    "                states_dec = states_enc\n",
    "\n",
    "        # Decoder gives the outputs batchwise\n",
    "        decoder_outputs, _ = self.decoder(DEC_IN, states_dec) \n",
    "        logits = self.fc(decoder_outputs)                      \n",
    "        return logits\n",
    "\n",
    "    def predict_greedy(self, batch):\n",
    "        # Greedy force outputs #\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "        DEC_IN = DEC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "        if self.bi_directional == True:\n",
    "            if self.enc_cell_type == \"LSTM\":\n",
    "                (h,c) = states_enc\n",
    "                states_enc = (combine_directions(h), combine_directions(c))\n",
    "            else:\n",
    "                states_enc = combine_directions(states_enc)\n",
    "            \n",
    "        # Final matrix\n",
    "        final_out = torch.zeros(batch_size, self.max_dec_seq_len, len(self.output_index_token), device=self.device)\n",
    "\n",
    "        # Initial decoder input (with start token)\n",
    "        in_ = torch.zeros(batch_size, 1, len(self.output_index_token), device=self.device)\n",
    "        in_[:, 0, 0] = 1.0\n",
    "        # Making the states correctly formatted\n",
    "        if self.dec_cell_type == \"LSTM\":\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc\n",
    "            else:\n",
    "                h = torch.zeros(self.num_layers, batch_size, self.decoder.hidden_size, device=self.device)\n",
    "                c = states_enc\n",
    "                states_dec = (h, c)\n",
    "        else:\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc[1]\n",
    "            else:\n",
    "                states_dec = states_enc\n",
    "\n",
    "        # Output to input\n",
    "        for t in range(self.max_dec_seq_len):\n",
    "            out_step, states_dec = self.decoder(in_, states_dec)  \n",
    "            logits_step = self.fc(out_step.squeeze(1))          \n",
    "            final_out[:, t, :] = logits_step\n",
    "\n",
    "            # Greedy argmax for next input\n",
    "            top1 = torch.argmax(logits_step, dim=1)              \n",
    "            in_ = torch.zeros(batch_size, 1, len(self.output_index_token), device=self.device)\n",
    "            in_[torch.arange(batch_size), 0, top1] = 1.0\n",
    "\n",
    "        return final_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb42ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:32:58.610579Z",
     "iopub.status.busy": "2025-05-19T14:32:58.610034Z",
     "iopub.status.idle": "2025-05-19T14:32:58.617916Z",
     "shell.execute_reply": "2025-05-19T14:32:58.617172Z",
     "shell.execute_reply.started": "2025-05-19T14:32:58.610554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fucntion for validation of the model # \n",
    "def validate_seq2seq(model, val_loader, device, val_type = \"greedy\", beam_width=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    correct_words = 0\n",
    "    total_words = 0\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tqdm_progress = tqdm(val_loader, desc=\"Predicting ...\")\n",
    "        for batch in tqdm_progress:\n",
    "            ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "            ENC_IN = ENC_IN.to(device)\n",
    "            DEC_IN = DEC_IN.to(device)\n",
    "            DEC_OUT = DEC_OUT.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            decoder_output = model(batch)\n",
    "\n",
    "            # Compute loss\n",
    "            vocab_size = decoder_output.size(-1)\n",
    "            decoder_output = decoder_output.view(-1, vocab_size)\n",
    "            decoder_target_indices = DEC_OUT.argmax(dim=-1).view(-1)\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target_indices)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Character-wise accuracy\n",
    "            if val_type == \"greedy\":\n",
    "                decoder_output = model.predict_greedy(batch)\n",
    "\n",
    "            #print(decoder_output.shape)\n",
    "            pred_tokens = decoder_output.argmax(dim=2)\n",
    "            true_tokens = DEC_OUT.argmax(dim=2)\n",
    "            #print(pred_tokens.shape)\n",
    "            \n",
    "            mask = true_tokens != 2  # Ignore PAD tokens\n",
    "            correct_chars += (pred_tokens[mask] == true_tokens[mask]).sum().item()\n",
    "            total_chars += mask.sum().item()\n",
    "\n",
    "            mask = true_tokens != 2  # Ignore PAD tokens\n",
    "            #print(mask.shape)\n",
    "            total_words += decoder_output.shape[0]\n",
    "            #print(pred_tokens[mask].shape)\n",
    "            chk_words = (mask.int() - (pred_tokens == true_tokens).int())\n",
    "            chk_words[mask == False] = 0\n",
    "            correct_words += (chk_words.sum(dim = 1) == 0).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_chars / total_chars if total_chars > 0 else 0.0\n",
    "    word_acc = correct_words / total_words if total_words > 0 else 0.0\n",
    "    return avg_loss, accuracy, word_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31ced2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:32:59.749242Z",
     "iopub.status.busy": "2025-05-19T14:32:59.748697Z",
     "iopub.status.idle": "2025-05-19T14:32:59.756708Z",
     "shell.execute_reply": "2025-05-19T14:32:59.755998Z",
     "shell.execute_reply.started": "2025-05-19T14:32:59.749221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainloop\n",
    "def train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs, device, beam_sizes = [3,5], run=None):\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=2)  # 2 is the padding index\n",
    "    max_val_char_acc = 0\n",
    "    max_val_word_acc = 0\n",
    "    print(\"Training of the model has started...\")\n",
    "    counter = 0\n",
    "    patience = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        tqdm_loader = tqdm(train_loader, desc=f\"Epoch : {epoch + 1} \", ncols=100)\n",
    "\n",
    "        for batch in tqdm_loader:\n",
    "            ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "            ENC_IN = ENC_IN.to(device)\n",
    "            DEC_IN = DEC_IN.to(device)\n",
    "            DEC_OUT = DEC_OUT.to(device)\n",
    "            # Move to device\n",
    "            decoder_output = model(batch)\n",
    "\n",
    "            # Reshape for loss\n",
    "            decoder_output = decoder_output.view(-1, decoder_output.size(-1))\n",
    "            decoder_target_indices = DEC_OUT.argmax(dim=-1).view(-1)\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target_indices)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            tqdm_loader.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        val_loss, val_acc, val_word_acc = validate_seq2seq(model, val_loader, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val Word Acc: {val_word_acc:.4f}\")\n",
    "\n",
    "        if run is not None:\n",
    "            run.log({\"train_loss_epoch\" : avg_loss, \"val_loss_epoch\" : val_loss, \"val_char_acc\" : val_acc, \"val_word_acc\" : val_word_acc})\n",
    "\n",
    "        if val_word_acc > max_val_word_acc:\n",
    "            max_val_char_acc = val_acc\n",
    "            max_val_word_acc = val_word_acc\n",
    "            torch.save(model.state_dict(),\"Vanilla_Best_model.pth\")\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter > patience:\n",
    "            break\n",
    "\n",
    "    if run is not None:\n",
    "        run.summary[\"max_val_char_acc\"] = max_val_char_acc\n",
    "        run.summary[\"max_val_word_acc\"] = max_val_word_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a307efb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:33:00.087521Z",
     "iopub.status.busy": "2025-05-19T14:33:00.086927Z",
     "iopub.status.idle": "2025-05-19T14:43:39.444685Z",
     "shell.execute_reply": "2025-05-19T14:43:39.443936Z",
     "shell.execute_reply.started": "2025-05-19T14:33:00.087497Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_143300-ogjxxba1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/A3_DA6401_DL/Vanilla_RNN/runs/ogjxxba1' target=\"_blank\">Best Model Vanilla S2S</a></strong> to <a href='https://wandb.ai/A3_DA6401_DL/Vanilla_RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/A3_DA6401_DL/Vanilla_RNN' target=\"_blank\">https://wandb.ai/A3_DA6401_DL/Vanilla_RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/A3_DA6401_DL/Vanilla_RNN/runs/ogjxxba1' target=\"_blank\">https://wandb.ai/A3_DA6401_DL/Vanilla_RNN/runs/ogjxxba1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the model has started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 1 : 100%|████████████████████████████████| 267/267 [00:38<00:00,  6.88it/s, Train Loss=2.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Train Loss: 2.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Val Loss: 2.0390 | Val Acc: 0.1724 | Val Word Acc: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 2 : 100%|███████████████████████████████| 267/267 [00:38<00:00,  6.92it/s, Train Loss=0.936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15] | Train Loss: 1.4576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15] | Val Loss: 0.9106 | Val Acc: 0.5602 | Val Word Acc: 0.1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 3 : 100%|███████████████████████████████| 267/267 [00:38<00:00,  6.91it/s, Train Loss=0.431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15] | Train Loss: 0.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15] | Val Loss: 0.4643 | Val Acc: 0.7740 | Val Word Acc: 0.4116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 4 : 100%|███████████████████████████████| 267/267 [00:38<00:00,  6.93it/s, Train Loss=0.324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15] | Train Loss: 0.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15] | Val Loss: 0.3615 | Val Acc: 0.8226 | Val Word Acc: 0.5103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 5 : 100%|████████████████████████████████| 267/267 [00:38<00:00,  6.92it/s, Train Loss=0.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15] | Train Loss: 0.2669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15] | Val Loss: 0.3292 | Val Acc: 0.8327 | Val Word Acc: 0.5443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 6 : 100%|███████████████████████████████| 267/267 [00:38<00:00,  6.90it/s, Train Loss=0.236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15] | Train Loss: 0.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15] | Val Loss: 0.3262 | Val Acc: 0.8354 | Val Word Acc: 0.5554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 7 : 100%|███████████████████████████████| 267/267 [00:39<00:00,  6.81it/s, Train Loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15] | Train Loss: 0.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15] | Val Loss: 0.3224 | Val Acc: 0.8443 | Val Word Acc: 0.5727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 8 : 100%|███████████████████████████████| 267/267 [00:39<00:00,  6.83it/s, Train Loss=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15] | Train Loss: 0.1514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15] | Val Loss: 0.3228 | Val Acc: 0.8427 | Val Word Acc: 0.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 9 : 100%|███████████████████████████████| 267/267 [00:38<00:00,  6.89it/s, Train Loss=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15] | Train Loss: 0.1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15] | Val Loss: 0.3266 | Val Acc: 0.8430 | Val Word Acc: 0.5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 10 : 100%|██████████████████████████████| 267/267 [00:38<00:00,  6.91it/s, Train Loss=0.132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15] | Train Loss: 0.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15] | Val Loss: 0.3258 | Val Acc: 0.8435 | Val Word Acc: 0.5784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 11 : 100%|██████████████████████████████| 267/267 [00:38<00:00,  6.92it/s, Train Loss=0.136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15] | Train Loss: 0.1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15] | Val Loss: 0.3478 | Val Acc: 0.8440 | Val Word Acc: 0.5793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 12 : 100%|█████████████████████████████| 267/267 [00:38<00:00,  6.93it/s, Train Loss=0.0851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15] | Train Loss: 0.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15] | Val Loss: 0.3546 | Val Acc: 0.8386 | Val Word Acc: 0.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 13 : 100%|█████████████████████████████| 267/267 [00:38<00:00,  6.89it/s, Train Loss=0.0707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15] | Train Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15] | Val Loss: 0.3464 | Val Acc: 0.8481 | Val Word Acc: 0.5902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 14 : 100%|█████████████████████████████| 267/267 [00:38<00:00,  6.91it/s, Train Loss=0.0585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15] | Train Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15] | Val Loss: 0.3583 | Val Acc: 0.8447 | Val Word Acc: 0.5818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 15 : 100%|█████████████████████████████| 267/267 [00:38<00:00,  6.91it/s, Train Loss=0.0958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15] | Train Loss: 0.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15] | Val Loss: 0.3670 | Val Acc: 0.8447 | Val Word Acc: 0.5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "config = {\n",
    "        \"learning_rate\" : 0.001,\n",
    "        \"dropout_rnn\" : 0.4, \n",
    "        \"batch_size\" :  256,\n",
    "        \"epochs\" : 15,\n",
    "        \"embedding_dim\" : 64,\n",
    "        \"num_layers\" : 5,\n",
    "        \"hidden_size_enc\" : 256,\n",
    "        \"enc_cell_type\" : \"GRU\",\n",
    "        \"dec_cell_type\" : \"LSTM\",\n",
    "        \"bi_directional\" : True,\n",
    "    }\n",
    "run = wandb.init(entity=\"A3_DA6401_DL\", project=\"Vanilla_RNN\", name=\"Best Model Vanilla S2S\", config=config)\n",
    "# Loading the datasets and dataloaders\n",
    "train_dataset = Dataset_Tamil(df_train)\n",
    "val_dataset = Dataset_Tamil(df_val, build_vocab=False, input_token_index=train_dataset.input_token_index, \n",
    "                            output_token_index=train_dataset.output_token_index, max_enc_seq_len=train_dataset.max_enc_seq_len,\n",
    "                            max_dec_seq_len=train_dataset.max_dec_seq_len)\n",
    "test_dataset = Dataset_Tamil(df_test, build_vocab=False, input_token_index=train_dataset.input_token_index, \n",
    "                            output_token_index=train_dataset.output_token_index, max_enc_seq_len=train_dataset.max_enc_seq_len,\n",
    "                            max_dec_seq_len=train_dataset.max_dec_seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Seq2Seq(input_token_index=train_dataset.input_token_index, output_token_index=train_dataset.output_token_index, max_dec_seq_len=train_dataset.max_dec_seq_len,\n",
    "                embedding_dim=config[\"embedding_dim\"], hidden_size_enc=config[\"hidden_size_enc\"], bi_directional=config[\"bi_directional\"], enc_cell=config[\"enc_cell_type\"], dec_cell=config[\"dec_cell_type\"], \n",
    "                num_layers=config[\"num_layers\"], dropout=config[\"dropout_rnn\"], device=device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs=config[\"epochs\"], device=device, run = run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6338bfbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:43:46.560290Z",
     "iopub.status.busy": "2025-05-19T14:43:46.559740Z",
     "iopub.status.idle": "2025-05-19T14:43:46.746595Z",
     "shell.execute_reply": "2025-05-19T14:43:46.745788Z",
     "shell.execute_reply.started": "2025-05-19T14:43:46.560268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = Seq2Seq(input_token_index=train_dataset.input_token_index, output_token_index=train_dataset.output_token_index, max_dec_seq_len=train_dataset.max_dec_seq_len,\n",
    "                embedding_dim=config[\"embedding_dim\"], hidden_size_enc=config[\"hidden_size_enc\"], bi_directional=config[\"bi_directional\"], enc_cell=config[\"enc_cell_type\"], dec_cell=config[\"dec_cell_type\"], \n",
    "                num_layers=config[\"num_layers\"], dropout=config[\"dropout_rnn\"], device=device).to(device)\n",
    "\n",
    "model_best.load_state_dict(torch.load(\"/kaggle/working/Vanilla_Best_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f4c912e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:51:27.422730Z",
     "iopub.status.busy": "2025-05-19T14:51:27.422023Z",
     "iopub.status.idle": "2025-05-19T14:51:30.671813Z",
     "shell.execute_reply": "2025-05-19T14:51:30.671270Z",
     "shell.execute_reply.started": "2025-05-19T14:51:27.422705Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.34643515089043864, 0.8480805578056257, 0.5901567306283872)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_seq2seq(model_best, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d3870b-c0fc-443f-ad82-295a1a3a7115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T14:54:25.289552Z",
     "iopub.status.busy": "2025-05-19T14:54:25.288820Z",
     "iopub.status.idle": "2025-05-19T14:54:28.544056Z",
     "shell.execute_reply": "2025-05-19T14:54:28.543475Z",
     "shell.execute_reply.started": "2025-05-19T14:54:25.289526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting ...: 100%|██████████| 27/27 [00:03<00:00,  8.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "_, test_char_acc, test_word_acc = validate_seq2seq(model_best, test_loader, device)\n",
    "\n",
    "if run is not None:\n",
    "    run.summary[\"test_char_acc\"] = test_char_acc\n",
    "    run.summary[\"test_word_acc\"] = test_word_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d99b02a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T15:01:43.976008Z",
     "iopub.status.busy": "2025-05-19T15:01:43.975683Z",
     "iopub.status.idle": "2025-05-19T15:01:43.983881Z",
     "shell.execute_reply": "2025-05-19T15:01:43.983104Z",
     "shell.execute_reply.started": "2025-05-19T15:01:43.975987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def write_outputs(model, data_loader, filename_csv):\n",
    "    tqdm_progress = tqdm(data_loader, desc=\"Writing...\")\n",
    "\n",
    "    list_in, list_out, list_pred = [], [], []\n",
    "    for batch in tqdm_progress:\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        out_pred = model.predict_greedy(batch)\n",
    "\n",
    "        for ix in range(ENC_IN.shape[0]):\n",
    "            str_in, str_out, str_pred = \"\", \"\", \"\"\n",
    "            input_word_vec = ENC_IN[ix].argmax(1)\n",
    "            output_word_vec = DEC_OUT[ix].argmax(1)\n",
    "            output_pred_vec = out_pred[ix].argmax(1)\n",
    "\n",
    "            for jx in range(train_dataset.max_dec_seq_len):\n",
    "                char = train_dataset.output_token_index_reversed[output_word_vec[jx].item()]\n",
    "                if char == \"\\n\":\n",
    "                    break\n",
    "                str_out += char                \n",
    "\n",
    "            for jx in range(train_dataset.max_dec_seq_len):\n",
    "                char = train_dataset.output_token_index_reversed[output_pred_vec[jx].item()]\n",
    "                if char == \"\\n\":\n",
    "                    break\n",
    "                str_pred += char      \n",
    "\n",
    "            for jx in range(train_dataset.max_enc_seq_len):\n",
    "                char = train_dataset.input_token_index_reversed[input_word_vec[jx].item()]\n",
    "                if char == \" \":\n",
    "                    break\n",
    "                str_in += char     \n",
    "\n",
    "            list_in.append(str_in)\n",
    "            list_out.append(str_out)\n",
    "            list_pred.append(str_pred)\n",
    "\n",
    "    pds = pd.DataFrame(data = {\"english\" : list_in, \"truth tamil\" : list_out, \"pred tamil\" : list_pred})\n",
    "    pds.to_csv(filename_csv, encoding=\"utf-8\", index=False)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19420188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T15:01:45.746581Z",
     "iopub.status.busy": "2025-05-19T15:01:45.745812Z",
     "iopub.status.idle": "2025-05-19T15:01:49.152130Z",
     "shell.execute_reply": "2025-05-19T15:01:49.151366Z",
     "shell.execute_reply.started": "2025-05-19T15:01:45.746555Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing...: 100%|██████████| 27/27 [00:03<00:00,  8.00it/s]\n"
     ]
    }
   ],
   "source": [
    "write_outputs(model, test_loader, \"Vanilla_predictions_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7443057,
     "sourceId": 11846133,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
