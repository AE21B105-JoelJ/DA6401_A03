{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f805463",
   "metadata": {},
   "source": [
    "# Assignment 03 - AE21B105\n",
    "This notebook will be used as the base version of testing the code written and for the sweeps later on. Then once finalized and all good this will be transfered to a script with command line arguments. Lets begin !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94cb030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "import lightning as L\n",
    "from lightning.pytorch import Trainer\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_printoptions(linewidth=50)\n",
    "np.set_printoptions(linewidth=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b935a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      native    latin  count\n",
      "0     ஃபியட்     fiat      2\n",
      "1     ஃபியட்   phiyat      1\n",
      "2     ஃபியட்    piyat      1\n",
      "3  ஃபிரான்ஸ்  firaans      1\n",
      "4  ஃபிரான்ஸ்   france      2\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "# Loading the dataset\n",
    "df_train = pd.read_csv('/home/joel/DA6401_DL/DA6401_A03/ta_lexicons/ta.translit.sampled.train.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "df_test = pd.read_csv('/home/joel/DA6401_DL/DA6401_A03/ta_lexicons/ta.translit.sampled.test.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "df_val = pd.read_csv('/home/joel/DA6401_DL/DA6401_A03/ta_lexicons/ta.translit.sampled.dev.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "\n",
    "\n",
    "# Show first few rows\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530609aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dataset for the Seq2Seq model\n",
    "class Dataset_Tamil(Dataset):\n",
    "    def __init__(self, dataframe, build_vocab=True, input_token_index=None, output_token_index=None,\n",
    "                 max_enc_seq_len=0, max_dec_seq_len=0):\n",
    "        \n",
    "        # Input variables\n",
    "        self.input_df = dataframe\n",
    "        self.input_words = []\n",
    "        self.output_words = []\n",
    "        # Characters of the language\n",
    "        self.input_characters = set()\n",
    "        self.output_characters = set()\n",
    "\n",
    "        # Iterating thorough the rows\n",
    "        for _, row in self.input_df.iterrows():\n",
    "            input_word = str(row[\"latin\"])\n",
    "            output_word = \"\\t\" + str(row[\"native\"]) + \"\\n\"\n",
    "            self.input_words.append(input_word)\n",
    "            self.output_words.append(output_word)\n",
    "        \n",
    "        if build_vocab:\n",
    "            self.build_vocab()\n",
    "        else:\n",
    "            # Token index for sequence building\n",
    "            self.input_token_index = input_token_index\n",
    "            self.output_token_index = output_token_index\n",
    "            # Heuristics lengths for the encoder decoder\n",
    "            self.max_enc_seq_len = max_enc_seq_len\n",
    "            self.max_dec_seq_len = max_dec_seq_len\n",
    "\n",
    "        # Finding the encoder/decoder tokens \n",
    "        self.total_encoder_tokens = len(self.input_token_index)\n",
    "        self.total_decoder_tokens = len(self.output_token_index)\n",
    "\n",
    "    def build_vocab(self):\n",
    "        # Building the vocabulary\n",
    "        self.input_characters = sorted(set(\" \".join(self.input_words)))\n",
    "        self.output_characters = sorted(set(\" \".join(self.output_words)))\n",
    "        # Adding the padding character if not present\n",
    "        if \" \" not in self.input_characters:\n",
    "            self.input_characters.append(\" \")\n",
    "        if \" \" not in self.output_characters:\n",
    "            self.output_characters.append(\" \")\n",
    "\n",
    "        # Fitting/Finding the necessary values from training data\n",
    "        self.input_token_index = {char: i for i, char in enumerate(self.input_characters)}\n",
    "        self.output_token_index = {char: i for i, char in enumerate(self.output_characters)}\n",
    "\n",
    "        self.max_enc_seq_len = max(len(txt) for txt in self.input_words)\n",
    "        self.max_dec_seq_len = max(len(txt) for txt in self.output_words)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_words)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_word = self.input_words[index]\n",
    "        output_word = self.output_words[index]\n",
    "\n",
    "        # Finding the input for each stages of the network\n",
    "        encoder_input = np.zeros((self.max_enc_seq_len, self.total_encoder_tokens), dtype=np.float32)\n",
    "        decoder_input = np.zeros((self.max_dec_seq_len, self.total_decoder_tokens), dtype=np.float32)\n",
    "        decoder_output = np.zeros((self.max_dec_seq_len, self.total_decoder_tokens), dtype=np.float32)\n",
    "\n",
    "        for t, char in enumerate(input_word):\n",
    "            if char in self.input_token_index:\n",
    "                encoder_input[t, self.input_token_index[char]] = 1.0\n",
    "        for t in range(len(input_word), self.max_enc_seq_len):\n",
    "            encoder_input[t, self.input_token_index[\" \"]] = 1.0\n",
    "\n",
    "        for t, char in enumerate(output_word):\n",
    "            if char in self.output_token_index:\n",
    "                decoder_input[t, self.output_token_index[char]] = 1.0\n",
    "                if t > 0:\n",
    "                    decoder_output[t - 1, self.output_token_index[char]] = 1.0\n",
    "        # Fill remaining positions with space character\n",
    "        for t in range(len(output_word), self.max_dec_seq_len):\n",
    "            decoder_input[t, self.output_token_index[\" \"]] = 1.0\n",
    "\n",
    "        # Ensure decoder_output is padded *after* last real target (t - 1 from above loop)\n",
    "        for t in range(len(output_word) - 1, self.max_dec_seq_len):\n",
    "            decoder_output[t, self.output_token_index[\" \"]] = 1.0\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(encoder_input),\n",
    "            torch.from_numpy(decoder_input),\n",
    "            torch.from_numpy(decoder_output)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acf2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets and dataloaders\n",
    "train_dataset = Dataset_Tamil(df_train)\n",
    "val_dataset = Dataset_Tamil(df_val, build_vocab=False, input_token_index=train_dataset.input_token_index, \n",
    "                            output_token_index=train_dataset.output_token_index, max_enc_seq_len=train_dataset.max_enc_seq_len,\n",
    "                            max_dec_seq_len=train_dataset.max_dec_seq_len)\n",
    "test_dataset = Dataset_Tamil(df_test, build_vocab=False, input_token_index=train_dataset.input_token_index, \n",
    "                            output_token_index=train_dataset.output_token_index, max_enc_seq_len=train_dataset.max_enc_seq_len,\n",
    "                            max_dec_seq_len=train_dataset.max_dec_seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3, cell_type=\"RNN\", num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type.upper()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.enc = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.enc = nn.GRU(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        else:\n",
    "            self.enc = nn.RNN(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            hidden, (hn, cn) = self.enc(x)\n",
    "            return hidden, (hn, cn)\n",
    "        else:\n",
    "            hidden, out = self.enc(x)\n",
    "            return hidden, out\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3, cell_type='RNN', num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.cell_type = cell_type.upper()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.dec = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.dec = nn.GRU(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        else:\n",
    "            self.dec = nn.RNN(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "\n",
    "    def forward(self, x, states):\n",
    "        if type(states) == tuple:\n",
    "            hidden, (hn, cn) = self.dec(x, states)\n",
    "            return hidden, (hn, cn)\n",
    "        else:\n",
    "            hidden, out = self.dec(x, states)\n",
    "            return hidden, out\n",
    "        \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_token_index, output_token_index, max_dec_seq_len, embedding_dim,hidden_size_enc, hidden_size_dec, nature=\"train\", enc_cell=\"LSTM\", dec_cell=\"LSTM\", num_layers=1, dropout=0.2, device=\"cpu\"):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.input_index_token = input_token_index\n",
    "        self.output_index_token = output_token_index\n",
    "        self.max_dec_seq_len = max_dec_seq_len\n",
    "        self.nature = nature\n",
    "        self.enc_cell_type = enc_cell.upper()\n",
    "        self.dec_cell_type = dec_cell.upper()\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Linear(in_features=len(self.input_index_token), out_features=embedding_dim)\n",
    "        self.embedding_act = nn.Tanh()\n",
    "        self.encoder = Encoder(input_size=embedding_dim, hidden_size=hidden_size_enc, dropout=dropout, cell_type=enc_cell, num_layers=num_layers).to(device)\n",
    "        self.decoder = Decoder(input_size=len(self.output_index_token), hidden_size=hidden_size_dec, dropout=dropout, cell_type=dec_cell, num_layers=num_layers).to(device)\n",
    "        self.device = device\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.fc = nn.Linear(in_features=hidden_size_dec, out_features=len(output_token_index))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "        DEC_IN = DEC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "        # Teacher forcing mode #    \n",
    "        # Making the states correctly formatted\n",
    "        if self.dec_cell_type == \"LSTM\": \n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc\n",
    "            else:\n",
    "                h = torch.zeros(self.num_layers, batch_size, self.decoder.hidden_size, device=self.device)\n",
    "                c = states_enc\n",
    "                states_dec = (h, c)\n",
    "        else:\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc[1]\n",
    "\n",
    "        # Decoder gives the outputs batchwise\n",
    "        decoder_outputs, _ = self.decoder(DEC_IN, states_dec)  # (B, T, H)\n",
    "        logits = self.fc(decoder_outputs)                      # (B, T, Vocab)\n",
    "        return logits\n",
    "\n",
    "    def predict_greedy(self, batch):\n",
    "        # Greedy force outputs #\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "        DEC_IN = DEC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "            \n",
    "        # Final matrix\n",
    "        final_out = torch.zeros(batch_size, self.max_dec_seq_len, len(self.output_index_token), device=self.device)\n",
    "\n",
    "        # Initial decoder input (with start token)\n",
    "        in_ = torch.zeros(batch_size, 1, len(self.output_index_token), device=self.device)\n",
    "        in_[:, 0, 0] = 1.0\n",
    "        # Making the states correctly formatted\n",
    "        if self.dec_cell_type == \"LSTM\":\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc\n",
    "            else:\n",
    "                h = torch.zeros(self.num_layers, batch_size, self.decoder.hidden_size, device=self.device)\n",
    "                c = states_enc\n",
    "                states_dec = (h, c)\n",
    "        else:\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc[1]\n",
    "\n",
    "        # Output to input\n",
    "        for t in range(self.max_dec_seq_len):\n",
    "            out_step, states_dec = self.decoder(in_, states_dec)  # (B, 1, H)\n",
    "            logits_step = self.fc(out_step.squeeze(1))            # (B, V)\n",
    "            final_out[:, t, :] = logits_step\n",
    "\n",
    "            # Greedy argmax for next input\n",
    "            top1 = torch.argmax(logits_step, dim=1)               # (B,)\n",
    "            in_ = torch.zeros(batch_size, 1, len(self.output_index_token), device=self.device)\n",
    "            in_[torch.arange(batch_size), 0, top1] = 1.0\n",
    "\n",
    "        return final_out\n",
    "    \n",
    "    def predict_beam_search(self, batch, beam_width = 3):\n",
    "        ENC_IN, _, _ = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "\n",
    "        # Encoder inputs #\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec2ea7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs, device):\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=2)  # 2 is the padding index\n",
    "\n",
    "    print(\"Training of the model has started...\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        tqdm_loader = tqdm(train_loader, desc=f\"Epoch : {epoch + 1} \", ncols=100)\n",
    "\n",
    "        for batch in tqdm_loader:\n",
    "            ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "            ENC_IN = ENC_IN.to(device)\n",
    "            DEC_IN = DEC_IN.to(device)\n",
    "            DEC_OUT = DEC_OUT.to(device)\n",
    "            # Move to device\n",
    "            decoder_output = model(batch)\n",
    "\n",
    "            # Reshape for loss\n",
    "            decoder_output = decoder_output.view(-1, decoder_output.size(-1))\n",
    "            decoder_target_indices = DEC_OUT.argmax(dim=-1).view(-1)\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target_indices)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            tqdm_loader.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        val_loss, val_acc, val_word_acc = validate_seq2seq(model, val_loader, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val Word Acc: {val_word_acc:.4f}\")\n",
    "\n",
    "def validate_seq2seq(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    correct_words = 0\n",
    "    total_words = 0\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "            ENC_IN = ENC_IN.to(device)\n",
    "            DEC_IN = DEC_IN.to(device)\n",
    "            DEC_OUT = DEC_OUT.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            decoder_output = model(batch)\n",
    "\n",
    "            # Compute loss\n",
    "            vocab_size = decoder_output.size(-1)\n",
    "            decoder_output = decoder_output.view(-1, vocab_size)\n",
    "            decoder_target_indices = DEC_OUT.argmax(dim=-1).view(-1)\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target_indices)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Character-wise accuracy\n",
    "            decoder_output = model.predict_greedy(batch)\n",
    "            #decoder_output = model.predict_beam_search(batch)\n",
    "\n",
    "            #print(decoder_output.shape)\n",
    "            pred_tokens = decoder_output.argmax(dim=2)#.view(DEC_OUT.size(0), DEC_OUT.size(1))\n",
    "            true_tokens = DEC_OUT.argmax(dim=2)\n",
    "            #print(pred_tokens.shape)\n",
    "            #print(true_tokens.shape)\n",
    "            \n",
    "            mask = true_tokens != 2  # Ignore PAD tokens\n",
    "            correct_chars += (pred_tokens[mask] == true_tokens[mask]).sum().item()\n",
    "            total_chars += mask.sum().item()\n",
    "\n",
    "            mask = true_tokens != 2  # Ignore PAD tokens\n",
    "            #print(mask.shape)\n",
    "            total_words += decoder_output.shape[0]\n",
    "            #print(pred_tokens[mask].shape)\n",
    "            chk_words = (mask.int() - (pred_tokens == true_tokens).int())\n",
    "            chk_words[mask == False] = 0\n",
    "            correct_words += (chk_words.sum(dim = 1) == 0).sum().item()\n",
    "\n",
    "            \"\"\"\n",
    "            ind = torch.arange(0,64)[chk_words.sum(dim = 1) == 0][0]      \n",
    "            print(pred_tokens[ind])\n",
    "            print(true_tokens[ind])\n",
    "            \"\"\"\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_chars / total_chars if total_chars > 0 else 0.0\n",
    "    word_acc = correct_words / total_words if total_words > 0 else 0.0\n",
    "    return avg_loss, accuracy, word_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7483e27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22, 16, 48, 15, 38,  1,  1, 48,  1,  1,\n",
      "         1, 48,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([22, 16, 48, 15, 38,  1,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([15, 30, 44, 15, 48,  1,  1,  1,  1, 48,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        40,  1, 16, 48,  1, 15, 31, 38])\n",
      "tensor([15, 30, 44, 15, 48,  1,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([30, 37, 25, 26, 48,  1,  1,  1,  1,  1,\n",
      "         1,  1, 48,  1, 15, 31, 38, 24, 48,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([30, 37, 25, 26, 48,  1,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([30, 38, 16, 48, 15, 26, 48,  1,  1,  1,\n",
      "        48,  1,  1,  1, 48,  1,  1,  1,  1,  1,\n",
      "        48,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([30, 38, 16, 48, 15, 26, 48,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([13, 25, 48, 25, 23, 48, 22, 16, 48, 15,\n",
      "        31, 48,  1, 31, 48,  1, 24, 48,  1,  1,\n",
      "         1,  1,  1,  1, 48,  1,  1,  1])\n",
      "tensor([13, 25, 48, 25, 23, 48, 22, 16, 48, 15,\n",
      "        31, 48,  1,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([25, 21, 38, 27, 38, 30, 48,  1,  1, 48,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1, 40,  1, 16, 48])\n",
      "tensor([25, 21, 38, 27, 38, 30, 48,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([25, 20, 16, 48, 15, 31, 38, 30, 48,  1,\n",
      "         1,  1, 48,  1, 31, 38, 37,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([25, 20, 16, 48, 15, 31, 38, 30, 48,  1,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([15, 20, 23, 48, 22, 37, 28, 48,  1, 37,\n",
      "         1,  1, 38, 27,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1, 40,  1, 16])\n",
      "tensor([15, 20, 23, 48, 22, 37, 28, 48,  1,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([25, 17, 40, 15, 48, 15, 31, 44,  1, 48,\n",
      "         1,  1,  1, 48,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([25, 17, 40, 15, 48, 15, 31, 44,  1,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([25, 42, 28, 38, 27, 33, 28, 48,  1,  1,\n",
      "         1, 48,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1, 40])\n",
      "tensor([25, 42, 28, 38, 27, 33, 28, 48,  1,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([33, 28, 38, 27, 38, 24, 48,  1, 37,  1,\n",
      "         1, 37,  1,  1,  1,  1,  1,  1, 40,  1,\n",
      "        16, 48,  1, 15, 31, 38, 24, 48])\n",
      "tensor([33, 28, 38, 27, 38, 24, 48,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([23, 46, 27, 38, 24, 37, 30, 48,  1, 37,\n",
      "         1,  1,  1, 48,  1, 15, 31, 48,  1,  1,\n",
      "         1,  1,  1, 40,  1, 48,  1, 15])\n",
      "tensor([23, 46, 27, 38, 24, 37, 30, 48,  1,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([ 4, 20, 38, 15, 31, 44,  1, 48,  1,  1,\n",
      "         1, 48,  1, 31, 38, 37, 24, 48,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([ 4, 20, 38, 15, 31, 44,  1,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([ 4, 30, 38,  1,  1, 48,  1, 37,  1,  1,\n",
      "         1,  1, 48,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1, 40,  1])\n",
      "tensor([ 4, 30, 38,  1,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([22, 38, 28, 44, 15, 31, 38, 30, 48,  1,\n",
      "         1,  1, 48,  1, 31, 38, 37,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([22, 38, 28, 44, 15, 31, 38, 30, 48,  1,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([25, 20, 16, 48, 15, 31, 40, 26, 48,  1,\n",
      "         1,  1, 48,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([25, 20, 16, 48, 15, 31, 40, 26, 48,  1,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([22, 43, 28, 48, 23, 48, 22, 42, 20, 40,\n",
      "        15, 48, 15,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([22, 43, 28, 48, 23, 48, 22, 42, 20, 40,\n",
      "        15, 48, 15,  1,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([22, 26, 38, 32, 15,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1, 40,  1, 16])\n",
      "tensor([22, 26, 38, 32, 15,  1,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([17, 42, 30, 40, 22, 48, 22, 38, 15, 48,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1, 40,  1, 16, 48])\n",
      "tensor([17, 42, 30, 40, 22, 48, 22, 38, 15, 48,\n",
      "         1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([22, 15, 20, 40, 15, 31, 48,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1, 40,  1, 16, 48,  1, 15])\n",
      "tensor([22, 15, 20, 40, 15, 31, 48,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([ 8, 31, 48, 31, 33, 28, 37, 15,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1, 40])\n",
      "tensor([ 8, 31, 48, 31, 33, 28, 37, 15,  1,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([30, 38, 16, 48, 15, 26, 48,  1,  1,  1,\n",
      "        48,  1,  1,  1, 48,  1,  1,  1,  1,  1,\n",
      "        48,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([30, 38, 16, 48, 15, 26, 48,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([ 5, 27, 48, 33, 40, 25, 48,  1,  1, 48,\n",
      "         1,  1,  1,  1,  1, 48,  1,  1,  1,  1,\n",
      "         1, 48,  1,  1,  1,  1,  1,  1])\n",
      "tensor([ 5, 27, 48, 33, 40, 25, 48,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([15, 46, 20, 48, 25, 37, 20, 40, 15, 31,\n",
      "        38, 30, 48,  1,  1,  1, 48,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1, 40,  1])\n",
      "tensor([15, 46, 20, 48, 25, 37, 20, 40, 15, 31,\n",
      "        38, 30, 48,  1,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n",
      "tensor([23, 41, 30, 15, 26, 37, 15,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([23, 41, 30, 15, 26, 37, 15,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mvalidate_seq2seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mvalidate_seq2seq\u001b[39m\u001b[34m(model, val_loader, device)\u001b[39m\n\u001b[32m     64\u001b[39m total_loss += loss.item()\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Character-wise accuracy\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m#decoder_output = model.predict_greedy(batch)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m decoder_output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_beam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m#print(decoder_output.shape)\u001b[39;00m\n\u001b[32m     71\u001b[39m pred_tokens = decoder_output.argmax(dim=\u001b[32m2\u001b[39m)\u001b[38;5;66;03m#.view(DEC_OUT.size(0), DEC_OUT.size(1))\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 218\u001b[39m, in \u001b[36mSeq2Seq.predict_beam_search\u001b[39m\u001b[34m(self, batch, beam_width)\u001b[39m\n\u001b[32m    215\u001b[39m decoder_input = new_decoder_input\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(states_dec, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     h = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_states_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (num_layers, B * beam, H)\u001b[39;00m\n\u001b[32m    219\u001b[39m     c = torch.cat(new_states_c, dim=\u001b[32m1\u001b[39m)\n\u001b[32m    220\u001b[39m     states_dec = (h, c)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "validate_seq2seq(model=model,val_loader=val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f3b9f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the model has started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 1 : 100%|██████████████████████████████| 1066/1066 [00:32<00:00, 33.19it/s, Train Loss=2.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 2.4201\n",
      "Epoch [1/20] | Val Loss: 2.1087 | Val Acc: 0.1522 | Val Word Acc: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 2 : 100%|██████████████████████████████| 1066/1066 [00:32<00:00, 32.84it/s, Train Loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] | Train Loss: 1.9526\n",
      "Epoch [2/20] | Val Loss: 1.8085 | Val Acc: 0.1832 | Val Word Acc: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 3 : 100%|███████████████████████████████| 1066/1066 [00:31<00:00, 34.09it/s, Train Loss=1.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] | Train Loss: 1.6340\n",
      "Epoch [3/20] | Val Loss: 1.4321 | Val Acc: 0.2827 | Val Word Acc: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 4 : 100%|██████████████████████████████| 1066/1066 [00:29<00:00, 36.23it/s, Train Loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] | Train Loss: 1.2928\n",
      "Epoch [4/20] | Val Loss: 1.1689 | Val Acc: 0.3533 | Val Word Acc: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 5 : 100%|█████████████████████████████| 1066/1066 [00:30<00:00, 34.73it/s, Train Loss=0.984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] | Train Loss: 1.0744\n",
      "Epoch [5/20] | Val Loss: 0.9880 | Val Acc: 0.4191 | Val Word Acc: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 6 : 100%|█████████████████████████████| 1066/1066 [00:29<00:00, 35.62it/s, Train Loss=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] | Train Loss: 0.9132\n",
      "Epoch [6/20] | Val Loss: 0.8397 | Val Acc: 0.4840 | Val Word Acc: 0.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 7 : 100%|█████████████████████████████| 1066/1066 [00:27<00:00, 38.67it/s, Train Loss=0.723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] | Train Loss: 0.7896\n",
      "Epoch [7/20] | Val Loss: 0.7300 | Val Acc: 0.5509 | Val Word Acc: 0.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 8 : 100%|█████████████████████████████| 1066/1066 [00:27<00:00, 38.73it/s, Train Loss=0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] | Train Loss: 0.6964\n",
      "Epoch [8/20] | Val Loss: 0.6606 | Val Acc: 0.5894 | Val Word Acc: 0.2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 9 : 100%|█████████████████████████████| 1066/1066 [00:27<00:00, 38.47it/s, Train Loss=0.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] | Train Loss: 0.6254\n",
      "Epoch [9/20] | Val Loss: 0.6088 | Val Acc: 0.6267 | Val Word Acc: 0.2533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 10 : 100%|████████████████████████████| 1066/1066 [00:29<00:00, 35.64it/s, Train Loss=0.705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] | Train Loss: 0.5712\n",
      "Epoch [10/20] | Val Loss: 0.5695 | Val Acc: 0.6517 | Val Word Acc: 0.2802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 11 : 100%|████████████████████████████| 1066/1066 [00:28<00:00, 37.95it/s, Train Loss=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] | Train Loss: 0.5253\n",
      "Epoch [11/20] | Val Loss: 0.5353 | Val Acc: 0.6770 | Val Word Acc: 0.3117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 12 : 100%|████████████████████████████| 1066/1066 [00:25<00:00, 41.30it/s, Train Loss=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] | Train Loss: 0.4879\n",
      "Epoch [12/20] | Val Loss: 0.5253 | Val Acc: 0.6852 | Val Word Acc: 0.3246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 13 : 100%|████████████████████████████| 1066/1066 [00:25<00:00, 41.72it/s, Train Loss=0.421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] | Train Loss: 0.4565\n",
      "Epoch [13/20] | Val Loss: 0.4828 | Val Acc: 0.7157 | Val Word Acc: 0.3766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 14 : 100%|████████████████████████████| 1066/1066 [00:25<00:00, 41.11it/s, Train Loss=0.445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] | Train Loss: 0.4289\n",
      "Epoch [14/20] | Val Loss: 0.4657 | Val Acc: 0.7255 | Val Word Acc: 0.3825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 15 : 100%|████████████████████████████| 1066/1066 [00:25<00:00, 41.48it/s, Train Loss=0.362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] | Train Loss: 0.4081\n",
      "Epoch [15/20] | Val Loss: 0.4570 | Val Acc: 0.7270 | Val Word Acc: 0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 16 : 100%|████████████████████████████| 1066/1066 [00:25<00:00, 41.59it/s, Train Loss=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] | Train Loss: 0.3888\n",
      "Epoch [16/20] | Val Loss: 0.4553 | Val Acc: 0.7285 | Val Word Acc: 0.3931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 17 : 100%|████████████████████████████| 1066/1066 [00:25<00:00, 41.49it/s, Train Loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] | Train Loss: 0.3721\n",
      "Epoch [17/20] | Val Loss: 0.4401 | Val Acc: 0.7385 | Val Word Acc: 0.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 18 : 100%|████████████████████████████| 1066/1066 [00:25<00:00, 41.48it/s, Train Loss=0.332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] | Train Loss: 0.3584\n",
      "Epoch [18/20] | Val Loss: 0.4259 | Val Acc: 0.7504 | Val Word Acc: 0.4318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 19 : 100%|████████████████████████████| 1066/1066 [00:25<00:00, 41.37it/s, Train Loss=0.273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] | Train Loss: 0.3444\n",
      "Epoch [19/20] | Val Loss: 0.4168 | Val Acc: 0.7545 | Val Word Acc: 0.4355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 20 : 100%|█████████████████████████████| 1066/1066 [00:25<00:00, 41.32it/s, Train Loss=0.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] | Train Loss: 0.3327\n",
      "Epoch [20/20] | Val Loss: 0.4215 | Val Acc: 0.7562 | Val Word Acc: 0.4456\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Seq2Seq(train_dataset.input_token_index,train_dataset.output_token_index, train_dataset.max_dec_seq_len,embedding_dim=50,hidden_size_enc=64, hidden_size_dec=64, num_layers=2, device=device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce92ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_loader:\n",
    "    ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "    break\n",
    "\n",
    "torch.set_printoptions(threshold=10000, linewidth=1000)\n",
    "DEC_OUT[2].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC_CHK = model.predict_greedy(batch)\n",
    "DEC_CHK[2].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs, device):\n",
    "    model.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        tqdm_loader = tqdm(train_loader, desc=f\"Epoch : {epoch} \")\n",
    "        for (encoder_input, decoder_input, decoder_target) in tqdm_loader:\n",
    "            # Move data to the appropriate device\n",
    "            encoder_input = encoder_input.to(device)\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            decoder_target = decoder_target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            hidden = model.encoder(encoder_input)\n",
    "            decoder_output, _ = model.decoder(decoder_input, hidden)\n",
    "\n",
    "            # Reshape output and target for loss calculation\n",
    "            batch_size, dec_seq_len, vocab_size = decoder_output.shape\n",
    "            decoder_output = decoder_output.view(-1, vocab_size)  # (batch_size * seq_len, vocab)\n",
    "            decoder_target = decoder_target.view(-1, vocab_size).argmax(dim=1)  # class indices\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            tqdm_loader.set_postfix({\n",
    "            \"Train loss (batch)\" : loss.item(),\n",
    "            })\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        val_loss, val_acc = validate_seq2seq(model, val_loader, device)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] | Val Loss: {val_loss:.4f} | Val Acc : {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "def validate_seq2seq(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_input, _, decoder_target in val_loader:\n",
    "            encoder_input = encoder_input.to(device)\n",
    "            decoder_target = decoder_target.to(device)\n",
    "\n",
    "            # ---- 1. Loss calculation (using teacher forcing only for loss) ----\n",
    "            hidden = model.encoder(encoder_input)\n",
    "            batch_size, dec_seq_len, vocab_size = decoder_target.shape\n",
    "\n",
    "            # Prepare decoder input using start tokens\n",
    "            decoder_input = torch.zeros(batch_size, dec_seq_len, vocab_size).to(device)\n",
    "            start_token_idx = model.output_index_token['\\t']\n",
    "            decoder_input[:, 0, start_token_idx] = 1.0\n",
    "\n",
    "            # Fill decoder input with shifted decoder_target (teacher forcing)\n",
    "            decoder_input[:, 1:] = decoder_target[:, :-1]\n",
    "\n",
    "            outputs, _ = model.decoder(decoder_input, hidden)\n",
    "            outputs_flat = outputs.view(-1, vocab_size)\n",
    "            targets_flat = decoder_target.view(-1, vocab_size).argmax(dim=1)\n",
    "            loss = loss_fn(outputs_flat, targets_flat)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            \"\"\"\n",
    "            # ---- 2. Accuracy calculation using model.predict() ----\n",
    "            for i in range(encoder_input.size(0)):\n",
    "                # Fix: Unsqueeze to make sure the input has batch size dimension\n",
    "                pred_seq = model.predict(encoder_input[i])  # Make it batch_size=1\n",
    "                true_seq = ''.join([\n",
    "                    model.output_index_token[idx.item()]\n",
    "                    for idx in decoder_target[i].argmax(dim=1)\n",
    "                    if model.output_index_token[idx.item()] not in ['\\t', '\\n']\n",
    "                ])\n",
    "                min_len = min(len(pred_seq), len(true_seq))\n",
    "                correct_chars += sum(pred_seq[j] == true_seq[j] for j in range(min_len))\n",
    "                total_chars += len(true_seq)\n",
    "            \"\"\"\n",
    "\n",
    "            # ---- 2. Accuracy calculation using model.predict() ----\n",
    "            # Fix: Unsqueeze to make sure the input has batch size dimension\n",
    "            pred_seq = model.predict_greedy(encoder_input)  # Make it batch_size=1\n",
    "            pred_max = torch.argmax(pred_seq, dim=2)\n",
    "            val_max = torch.argmax(decoder_target, dim=2)\n",
    "\n",
    "            total_correct = torch.sum(pred_max[val_max!=0] == val_max[val_max!=1])\n",
    "            total_avail = torch.sum(val_max!=1)\n",
    "\n",
    "            correct_chars += total_correct\n",
    "            total_chars += total_avail\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_chars / total_chars if total_chars > 0 else 0.0\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}, Character Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a03de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Seq2Seq(train_dataset.input_token_index,train_dataset.output_token_index, train_dataset.max_dec_seq_len,64, device).to(device)\n",
    "\n",
    "\n",
    "validate_seq2seq(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34481d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Seq2Seq(train_dataset.input_token_index,train_dataset.output_token_index, 512, device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs=10, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_index_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[120][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"123abc\"\n",
    "str2 = \"cde456\"\n",
    "list1 = []\n",
    "list1.append(str1)\n",
    "list1.append(str2)\n",
    "\n",
    "sorted(set(\" \".join(list1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3944aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"hello\",5],[\"hel\",3]], columns=[\"A\",\"B\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55edb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(str):\n",
    "    return \"\\t\" + str + \"\\n\"\n",
    "\n",
    "df[\"A\"] = df[\"A\"].apply(f)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
