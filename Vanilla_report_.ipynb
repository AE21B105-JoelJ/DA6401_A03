{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51387b6b",
   "metadata": {},
   "source": [
    "# Vanilla Seq2Seq Report Tester Notebook\n",
    "This notebook is used to take the best model from the sweep retrain the model using appropriate callbacks and then predict on the test set and save it and also create some visualizations if required. Without much details lets get into the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa392ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries #\n",
    "# Importing the necessary libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as Fn\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "from lightning.pytorch import Trainer\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "# Loading the dataset\n",
    "df_train = pd.read_csv('/home/joel/DA6401_DL/DA6401_A03/ta_lexicons/ta.translit.sampled.train.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "df_test = pd.read_csv('/home/joel/DA6401_DL/DA6401_A03/ta_lexicons/ta.translit.sampled.test.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])\n",
    "df_val = pd.read_csv('/home/joel/DA6401_DL/DA6401_A03/ta_lexicons/ta.translit.sampled.dev.tsv', sep='\\t',  header=None, names=[\"native\",\"latin\",\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24374e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset for the model to fit #\n",
    "class Dataset_Tamil(Dataset):\n",
    "    def __init__(self, dataframe, build_vocab=True, input_token_index=None, output_token_index=None,\n",
    "                 max_enc_seq_len=0, max_dec_seq_len=0):\n",
    "        \n",
    "        # Input variables\n",
    "        self.input_df = dataframe\n",
    "        self.input_words = []\n",
    "        self.output_words = []\n",
    "        # Characters of the language\n",
    "        self.input_characters = set()\n",
    "        self.output_characters = set()\n",
    "\n",
    "        # Iterating thorough the rows\n",
    "        for _, row in self.input_df.iterrows():\n",
    "            input_word = str(row[\"latin\"])\n",
    "            output_word = \"\\t\" + str(row[\"native\"]) + \"\\n\"\n",
    "            self.input_words.append(input_word)\n",
    "            self.output_words.append(output_word)\n",
    "        \n",
    "        if build_vocab:\n",
    "            self.build_vocab()\n",
    "        else:\n",
    "            # Token index for sequence building\n",
    "            self.input_token_index = input_token_index\n",
    "            self.output_token_index = output_token_index\n",
    "            # Heuristics lengths for the encoder decoder\n",
    "            self.max_enc_seq_len = max_enc_seq_len\n",
    "            self.max_dec_seq_len = max_dec_seq_len\n",
    "\n",
    "        # Finding the encoder/decoder tokens \n",
    "        self.total_encoder_tokens = len(self.input_token_index)\n",
    "        self.total_decoder_tokens = len(self.output_token_index)\n",
    "\n",
    "    def build_vocab(self):\n",
    "        # Building the vocabulary\n",
    "        self.input_characters = sorted(set(\" \".join(self.input_words)))\n",
    "        self.output_characters = sorted(set(\" \".join(self.output_words)))\n",
    "        # Adding the padding character if not present\n",
    "        if \" \" not in self.input_characters:\n",
    "            self.input_characters.append(\" \")\n",
    "        if \" \" not in self.output_characters:\n",
    "            self.output_characters.append(\" \")\n",
    "\n",
    "        # Fitting/Finding the necessary values from training data\n",
    "        self.input_token_index = {char: i for i, char in enumerate(self.input_characters)}\n",
    "        self.output_token_index = {char: i for i, char in enumerate(self.output_characters)}\n",
    "\n",
    "        self.max_enc_seq_len = max(len(txt) for txt in self.input_words)\n",
    "        self.max_dec_seq_len = max(len(txt) for txt in self.output_words)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_words)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_word = self.input_words[index]\n",
    "        output_word = self.output_words[index]\n",
    "\n",
    "        # Finding the input for each stages of the network\n",
    "        encoder_input = np.zeros((self.max_enc_seq_len, self.total_encoder_tokens), dtype=np.float32)\n",
    "        decoder_input = np.zeros((self.max_dec_seq_len, self.total_decoder_tokens), dtype=np.float32)\n",
    "        decoder_output = np.zeros((self.max_dec_seq_len, self.total_decoder_tokens), dtype=np.float32)\n",
    "\n",
    "        for t, char in enumerate(input_word):\n",
    "            if char in self.input_token_index:\n",
    "                encoder_input[t, self.input_token_index[char]] = 1.0\n",
    "        for t in range(len(input_word), self.max_enc_seq_len):\n",
    "            encoder_input[t, self.input_token_index[\" \"]] = 1.0\n",
    "\n",
    "        for t, char in enumerate(output_word):\n",
    "            if char in self.output_token_index:\n",
    "                decoder_input[t, self.output_token_index[char]] = 1.0\n",
    "                if t > 0:\n",
    "                    decoder_output[t - 1, self.output_token_index[char]] = 1.0\n",
    "        # Fill remaining positions with space character\n",
    "        for t in range(len(output_word), self.max_dec_seq_len):\n",
    "            decoder_input[t, self.output_token_index[\" \"]] = 1.0\n",
    "\n",
    "        # Ensure decoder_output is padded *after* last real target (t - 1 from above loop)\n",
    "        for t in range(len(output_word) - 1, self.max_dec_seq_len):\n",
    "            decoder_output[t, self.output_token_index[\" \"]] = 1.0\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(encoder_input),\n",
    "            torch.from_numpy(decoder_input),\n",
    "            torch.from_numpy(decoder_output)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model classes definitions #\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3, cell_type=\"RNN\", num_layers=1, bi_directional=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type.upper()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.enc = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.enc = nn.GRU(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "        else:\n",
    "            self.enc = nn.RNN(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers, bidirectional=bi_directional)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            hidden, (hn, cn) = self.enc(x)\n",
    "            return hidden, (hn, cn)\n",
    "        else:\n",
    "            hidden, out = self.enc(x)\n",
    "            return hidden, out\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3, cell_type='RNN', num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.cell_type = cell_type.upper()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.dec = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        elif self.cell_type == 'GRU':\n",
    "            self.dec = nn.GRU(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "        else:\n",
    "            self.dec = nn.RNN(input_size, hidden_size, batch_first=True, dropout=self.dropout, num_layers=self.num_layers)\n",
    "\n",
    "    def forward(self, x, states):\n",
    "        if type(states) == tuple:\n",
    "            hidden, (hn, cn) = self.dec(x, states)\n",
    "            return hidden, (hn, cn)\n",
    "        else:\n",
    "            hidden, out = self.dec(x, states)\n",
    "            return hidden, out\n",
    "        \n",
    "# Helper function\n",
    "def combine_directions(hidden):\n",
    "    # hidden shape: (num_layers * 2, B, H1)\n",
    "    layers = []\n",
    "    for i in range(0, hidden.size(0), 2):  # 0,2,4,...\n",
    "        fwd = hidden[i]\n",
    "        bwd = hidden[i + 1]\n",
    "        combined = torch.cat((fwd, bwd), dim=-1)  # shape: (B, 2*H1)\n",
    "        layers.append(combined)\n",
    "    return torch.stack(layers)  # shape: (num_layers, B, 2*H1)\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_token_index, output_token_index, max_dec_seq_len, embedding_dim,hidden_size_enc, bi_directional,\n",
    "            nature=\"train\", enc_cell=\"LSTM\", dec_cell=\"LSTM\", num_layers=1,dropout=0.2, device=\"cpu\"):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.input_index_token = input_token_index\n",
    "        self.output_index_token = output_token_index\n",
    "        self.max_dec_seq_len = max_dec_seq_len\n",
    "        self.nature = nature\n",
    "        self.enc_cell_type = enc_cell.upper()\n",
    "        self.dec_cell_type = dec_cell.upper()\n",
    "        self.num_layers= num_layers\n",
    "        self.bi_directional = bi_directional\n",
    "        self.hidden_size_enc = hidden_size_enc\n",
    "        self.hidden_size_dec = (1 + int(self.bi_directional == True))*hidden_size_enc\n",
    "        self.embedding = nn.Linear(in_features=len(self.input_index_token), out_features=embedding_dim)\n",
    "        self.embedding_act = nn.Tanh()\n",
    "        self.encoder = Encoder(input_size=embedding_dim, hidden_size=hidden_size_enc, dropout=dropout, cell_type=enc_cell, num_layers=num_layers, bi_directional=self.bi_directional).to(device)\n",
    "        self.decoder = Decoder(input_size=len(self.output_index_token), hidden_size=self.hidden_size_dec, dropout=dropout, cell_type=dec_cell, num_layers=num_layers).to(device)\n",
    "        self.device = device\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.fc = nn.Linear(in_features=self.hidden_size_dec, out_features=len(output_token_index))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "        DEC_IN = DEC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "        if self.bi_directional == True:\n",
    "            if self.enc_cell_type == \"LSTM\":\n",
    "                (h,c) = states_enc\n",
    "                states_enc = (combine_directions(h), combine_directions(c))\n",
    "            else:\n",
    "                states_enc = combine_directions(states_enc)\n",
    "\n",
    "        # Teacher forcing mode #    \n",
    "        # Making the states correctly formatted\n",
    "        if self.dec_cell_type == \"LSTM\": \n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc\n",
    "            else:\n",
    "                h = torch.zeros(self.num_layers, batch_size, self.decoder.hidden_size, device=self.device)\n",
    "                c = states_enc\n",
    "                states_dec = (h, c)\n",
    "        else:\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc[1]\n",
    "            else:\n",
    "                states_dec = states_enc\n",
    "\n",
    "        # Decoder gives the outputs batchwise\n",
    "        decoder_outputs, _ = self.decoder(DEC_IN, states_dec)  # (B, T, H)\n",
    "        logits = self.fc(decoder_outputs)                      # (B, T, Vocab)\n",
    "        return logits\n",
    "\n",
    "    def predict_greedy(self, batch):\n",
    "        # Greedy force outputs #\n",
    "        ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "        DEC_IN = DEC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "        if self.bi_directional == True:\n",
    "            if self.enc_cell_type == \"LSTM\":\n",
    "                (h,c) = states_enc\n",
    "                states_enc = (combine_directions(h), combine_directions(c))\n",
    "            else:\n",
    "                states_enc = combine_directions(states_enc)\n",
    "            \n",
    "        # Final matrix\n",
    "        final_out = torch.zeros(batch_size, self.max_dec_seq_len, len(self.output_index_token), device=self.device)\n",
    "\n",
    "        # Initial decoder input (with start token)\n",
    "        in_ = torch.zeros(batch_size, 1, len(self.output_index_token), device=self.device)\n",
    "        in_[:, 0, 0] = 1.0\n",
    "        # Making the states correctly formatted\n",
    "        if self.dec_cell_type == \"LSTM\":\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc\n",
    "            else:\n",
    "                h = torch.zeros(self.num_layers, batch_size, self.decoder.hidden_size, device=self.device)\n",
    "                c = states_enc\n",
    "                states_dec = (h, c)\n",
    "        else:\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc[1]\n",
    "            else:\n",
    "                states_dec = states_enc\n",
    "\n",
    "        # Output to input\n",
    "        for t in range(self.max_dec_seq_len):\n",
    "            out_step, states_dec = self.decoder(in_, states_dec)  # (B, 1, H)\n",
    "            logits_step = self.fc(out_step.squeeze(1))            # (B, V)\n",
    "            final_out[:, t, :] = logits_step\n",
    "\n",
    "            # Greedy argmax for next input\n",
    "            top1 = torch.argmax(logits_step, dim=1)               # (B,)\n",
    "            in_ = torch.zeros(batch_size, 1, len(self.output_index_token), device=self.device)\n",
    "            in_[torch.arange(batch_size), 0, top1] = 1.0\n",
    "\n",
    "        return final_out\n",
    "\n",
    "    def predict_beam_search(self, batch, beam_width=3):\n",
    "        ENC_IN, _, _ = batch\n",
    "        ENC_IN = ENC_IN.to(self.device)\n",
    "\n",
    "        batch_size = ENC_IN.size(0)\n",
    "        input_embedding = self.embedding_act(self.embedding(ENC_IN))\n",
    "        hidden_enc, states_enc = self.encoder(input_embedding)\n",
    "\n",
    "        if self.bi_directional == True:\n",
    "            if self.enc_cell_type == \"LSTM\":\n",
    "                (h,c) = states_enc\n",
    "                states_enc = (combine_directions(h), combine_directions(c))\n",
    "            else:\n",
    "                states_enc = combine_directions(states_enc)\n",
    "\n",
    "        final_out = torch.zeros(batch_size, self.max_dec_seq_len, len(self.output_index_token), device=self.device)\n",
    "\n",
    "        if self.dec_cell_type == \"LSTM\":\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc\n",
    "            else:\n",
    "                h = torch.zeros(self.num_layers, batch_size, self.decoder.hidden_size, device=self.device)\n",
    "                c = states_enc\n",
    "                states_dec = (h, c)\n",
    "        else:\n",
    "            if isinstance(states_enc, tuple):\n",
    "                states_dec = states_enc[1]\n",
    "            else:\n",
    "                states_dec = states_enc\n",
    "\n",
    "        for batch_idx in range(batch_size):\n",
    "            in_ = torch.zeros(beam_width, 1, len(self.output_index_token), device=self.device)\n",
    "            in_[:, 0, 0] = 1.0\n",
    "\n",
    "            beam_dict_old = {x: {\"sequence\": [0], \"states\": None, \"probs\": 0.0} for x in range(beam_width)}\n",
    "\n",
    "            if self.dec_cell_type == \"LSTM\":\n",
    "                for ix in range(beam_width):\n",
    "                    beam_dict_old[ix][\"states\"] = (\n",
    "                        states_dec[0][:, batch_idx:batch_idx+1, :].repeat(1, 1, 1),\n",
    "                        states_dec[1][:, batch_idx:batch_idx+1, :].repeat(1, 1, 1)\n",
    "                    )\n",
    "            else:\n",
    "                for ix in range(beam_width):\n",
    "                    beam_dict_old[ix][\"states\"] = states_dec[:, batch_idx:batch_idx+1, :].repeat(1, 1, 1)\n",
    "\n",
    "            for t in range(self.max_dec_seq_len):\n",
    "                in_ = torch.zeros(beam_width, 1, len(self.output_index_token), device=self.device)\n",
    "                states_h_tensor = torch.zeros((self.num_layers, beam_width, self.decoder.hidden_size), device=self.device)\n",
    "                states_c_tensor = torch.zeros((self.num_layers, beam_width, self.decoder.hidden_size), device=self.device)\n",
    "\n",
    "                for ix in range(beam_width):\n",
    "                    in_[ix, 0, beam_dict_old[ix][\"sequence\"][-1]] = 1\n",
    "                    if self.dec_cell_type == \"LSTM\":\n",
    "                        states_h_tensor[:, ix, :] = beam_dict_old[ix][\"states\"][0].squeeze(1)\n",
    "                        states_c_tensor[:, ix, :] = beam_dict_old[ix][\"states\"][1].squeeze(1)\n",
    "                    else:\n",
    "                        states_h_tensor[:, ix, :] = beam_dict_old[ix][\"states\"].squeeze(1)\n",
    "\n",
    "                states_dec_i = (states_h_tensor, states_c_tensor) if self.dec_cell_type == \"LSTM\" else states_h_tensor\n",
    "                out_step, states_dec_out = self.decoder(in_, states_dec_i)\n",
    "                logits_step = self.fc(out_step.squeeze(1))\n",
    "                log_prob = F.log_softmax(logits_step, dim=1)\n",
    "\n",
    "                # Add beam scores\n",
    "                for iy in range(beam_width):\n",
    "                    log_prob[iy] += beam_dict_old[iy][\"probs\"]\n",
    "\n",
    "                # Get top k sequences\n",
    "                all_candidates = []\n",
    "                for i in range(beam_width):\n",
    "                    topk_log_probs, topk_indices = torch.topk(log_prob[i], beam_width)\n",
    "                    for k in range(beam_width):\n",
    "                        token_id = topk_indices[k].item()\n",
    "                        new_seq = beam_dict_old[i][\"sequence\"] + [token_id]\n",
    "                        new_prob = topk_log_probs[k].item()\n",
    "                        if self.dec_cell_type == \"LSTM\":\n",
    "                            new_states = (\n",
    "                                states_dec_out[0][:, i:i+1, :],\n",
    "                                states_dec_out[1][:, i:i+1, :]\n",
    "                            )\n",
    "                        else:\n",
    "                            new_states = states_dec_out[:, i:i+1, :]\n",
    "                        all_candidates.append((new_prob, new_seq, new_states))\n",
    "\n",
    "                # Select top beam_width candidates\n",
    "                all_candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "                beam_dict_old = {\n",
    "                    i: {\"probs\": all_candidates[i][0], \"sequence\": all_candidates[i][1], \"states\": all_candidates[i][2]}\n",
    "                    for i in range(beam_width)\n",
    "                }\n",
    "\n",
    "            best_seq = beam_dict_old[0][\"sequence\"][1:]\n",
    "            for t in range(len(best_seq)):\n",
    "                final_out[batch_idx, t, best_seq[t]] = 1.0\n",
    "\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion for validation of the model # \n",
    "def validate_seq2seq(model, val_loader, device, val_type = \"greedy\", beam_width=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    correct_words = 0\n",
    "    total_words = 0\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "            ENC_IN = ENC_IN.to(device)\n",
    "            DEC_IN = DEC_IN.to(device)\n",
    "            DEC_OUT = DEC_OUT.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            decoder_output = model(batch)\n",
    "\n",
    "            # Compute loss\n",
    "            vocab_size = decoder_output.size(-1)\n",
    "            decoder_output = decoder_output.view(-1, vocab_size)\n",
    "            decoder_target_indices = DEC_OUT.argmax(dim=-1).view(-1)\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target_indices)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Character-wise accuracy\n",
    "            if val_type == \"greedy\":\n",
    "                decoder_output = model.predict_greedy(batch)\n",
    "            else:\n",
    "                decoder_output = model.predict_beam_search(batch, beam_width=beam_width)\n",
    "\n",
    "            #print(decoder_output.shape)\n",
    "            pred_tokens = decoder_output.argmax(dim=2)#.view(DEC_OUT.size(0), DEC_OUT.size(1))\n",
    "            true_tokens = DEC_OUT.argmax(dim=2)\n",
    "            #print(pred_tokens.shape)\n",
    "            #print(true_tokens.shape)\n",
    "            \n",
    "            mask = true_tokens != 2  # Ignore PAD tokens\n",
    "            correct_chars += (pred_tokens[mask] == true_tokens[mask]).sum().item()\n",
    "            total_chars += mask.sum().item()\n",
    "\n",
    "            mask = true_tokens != 2  # Ignore PAD tokens\n",
    "            #print(mask.shape)\n",
    "            total_words += decoder_output.shape[0]\n",
    "            #print(pred_tokens[mask].shape)\n",
    "            chk_words = (mask.int() - (pred_tokens == true_tokens).int())\n",
    "            chk_words[mask == False] = 0\n",
    "            correct_words += (chk_words.sum(dim = 1) == 0).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_chars / total_chars if total_chars > 0 else 0.0\n",
    "    word_acc = correct_words / total_words if total_words > 0 else 0.0\n",
    "    return avg_loss, accuracy, word_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainloop\n",
    "def train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs, device, beam_sizes = [3,5], run=None):\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=2)  # 2 is the padding index\n",
    "    max_val_char_acc = 0\n",
    "    max_val_word_acc = 0\n",
    "    print(\"Training of the model has started...\")\n",
    "    counter = 0\n",
    "    patience = 7\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        tqdm_loader = tqdm(train_loader, desc=f\"Epoch : {epoch + 1} \", ncols=100)\n",
    "\n",
    "        for batch in tqdm_loader:\n",
    "            ENC_IN, DEC_IN, DEC_OUT = batch\n",
    "            ENC_IN = ENC_IN.to(device)\n",
    "            DEC_IN = DEC_IN.to(device)\n",
    "            DEC_OUT = DEC_OUT.to(device)\n",
    "            # Move to device\n",
    "            decoder_output = model(batch)\n",
    "\n",
    "            # Reshape for loss\n",
    "            decoder_output = decoder_output.view(-1, decoder_output.size(-1))\n",
    "            decoder_target_indices = DEC_OUT.argmax(dim=-1).view(-1)\n",
    "\n",
    "            loss = loss_fn(decoder_output, decoder_target_indices)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            tqdm_loader.set_postfix({\"Train Loss\": loss.item()})\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        val_loss, val_acc, val_word_acc = validate_seq2seq(model, val_loader, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val Word Acc: {val_word_acc:.4f}\")\n",
    "\n",
    "        if run is not None:\n",
    "            run.log({\"train_loss_epoch\" : avg_loss, \"val_loss_epoch\" : val_loss, \"val_char_acc\" : val_acc, \"val_word_acc\" : val_word_acc})\n",
    "\n",
    "        if val_word_acc > max_val_word_acc or val_acc > max_val_char_acc:\n",
    "            max_val_char_acc = val_acc\n",
    "            max_val_word_acc = val_word_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter > patience:\n",
    "            break\n",
    "\n",
    "    if run is not None:\n",
    "        run.summary[\"max_val_char_acc\"] = max_val_char_acc\n",
    "        run.summary[\"max_val_word_acc\"] = max_val_word_acc\n",
    "        #for beam_size in beam_sizes:\n",
    "        #    val_loss, val_acc, val_word_acc = validate_seq2seq(model, val_loader, device, val_type=\"beam\", beam_width=beam_size)\n",
    "        #    run.summary[f\"max_val_char_acc_bs_{beam_size}\"] = val_acc\n",
    "        #    run.summary[f\"max_val_word_acc_bs_{beam_size}\"] = val_word_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "config = {\n",
    "        \"learning_rate\" : 0.001,\n",
    "        \"dropout_rnn\" : 0.4, \n",
    "        \"batch_size\" :  256,\n",
    "        \"epochs\" : 1,\n",
    "        \"embedding_dim\" : 64,\n",
    "        \"num_layers\" : 5,\n",
    "        \"hidden_size_enc\" : 256,\n",
    "        \"enc_cell_type\" : \"GRU\",\n",
    "        \"dec_cell_type\" : \"LSTM\",\n",
    "        \"bi_directional\" : True,\n",
    "    }\n",
    "\n",
    "# Loading the datasets and dataloaders\n",
    "train_dataset = Dataset_Tamil(df_train)\n",
    "val_dataset = Dataset_Tamil(df_val, build_vocab=False, input_token_index=train_dataset.input_token_index, \n",
    "                            output_token_index=train_dataset.output_token_index, max_enc_seq_len=train_dataset.max_enc_seq_len,\n",
    "                            max_dec_seq_len=train_dataset.max_dec_seq_len)\n",
    "test_dataset = Dataset_Tamil(df_test, build_vocab=False, input_token_index=train_dataset.input_token_index, \n",
    "                            output_token_index=train_dataset.output_token_index, max_enc_seq_len=train_dataset.max_enc_seq_len,\n",
    "                            max_dec_seq_len=train_dataset.max_dec_seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Seq2Seq(input_token_index=train_dataset.input_token_index, output_token_index=train_dataset.output_token_index, max_dec_seq_len=train_dataset.max_dec_seq_len,\n",
    "                embedding_dim=config[\"embedding_dim\"], hidden_size_enc=config[\"hidden_size_enc\"], bi_directional=config[\"bi_directional\"], enc_cell=config[\"enc_cell_type\"], dec_cell=config[\"dec_cell_type\"], \n",
    "                num_layers=config[\"num_layers\"], dropout=config[\"dropout_rnn\"], device=device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "train_seq2seq(model, train_loader, val_loader, optimizer, num_epochs=config[\"epochs\"], device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
